wandb: WARNING `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id rld9zw30.
wandb: Tracking run with wandb version 0.13.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Logging to ./temp/models/tsp_diffusion/rld9zw30
Loaded "./temp/data/tsp/tsp100_auto_train.txt" with 100000 lines
Loaded "./temp/data/tsp/tsp100_auto_test.txt" with 1000 lines
Loaded "./temp/data/tsp/tsp100_auto_val.txt" with 1000 lines
Using 16bit native Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
----------------------------------------------------------------------------------------------------
GNNEncoder(
  (node_embed): Linear(in_features=256, out_features=256, bias=True)
  (edge_embed): Linear(in_features=256, out_features=256, bias=True)
  (pos_embed): PositionEmbeddingSine()
  (edge_pos_embed): ScalarEmbeddingSine()
  (time_embed): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=128, bias=True)
  )
  (out): Sequential(
    (0): GroupNorm32(32, 256, eps=1e-05, affine=True)
    (1): ReLU()
    (2): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
  )
  (layers): ModuleList(
    (0): GNNLayer(
      (U): Linear(in_features=256, out_features=256, bias=True)
      (V): Linear(in_features=256, out_features=256, bias=True)
      (A): Linear(in_features=256, out_features=256, bias=True)
      (B): Linear(in_features=256, out_features=256, bias=True)
      (C): Linear(in_features=256, out_features=256, bias=True)
      (norm_h): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (norm_e): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (1): GNNLayer(
      (U): Linear(in_features=256, out_features=256, bias=True)
      (V): Linear(in_features=256, out_features=256, bias=True)
      (A): Linear(in_features=256, out_features=256, bias=True)
      (B): Linear(in_features=256, out_features=256, bias=True)
      (C): Linear(in_features=256, out_features=256, bias=True)
      (norm_h): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (norm_e): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (2): GNNLayer(
      (U): Linear(in_features=256, out_features=256, bias=True)
      (V): Linear(in_features=256, out_features=256, bias=True)
      (A): Linear(in_features=256, out_features=256, bias=True)
      (B): Linear(in_features=256, out_features=256, bias=True)
      (C): Linear(in_features=256, out_features=256, bias=True)
      (norm_h): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (norm_e): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (3): GNNLayer(
      (U): Linear(in_features=256, out_features=256, bias=True)
      (V): Linear(in_features=256, out_features=256, bias=True)
      (A): Linear(in_features=256, out_features=256, bias=True)
      (B): Linear(in_features=256, out_features=256, bias=True)
      (C): Linear(in_features=256, out_features=256, bias=True)
      (norm_h): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (norm_e): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (4): GNNLayer(
      (U): Linear(in_features=256, out_features=256, bias=True)
      (V): Linear(in_features=256, out_features=256, bias=True)
      (A): Linear(in_features=256, out_features=256, bias=True)
      (B): Linear(in_features=256, out_features=256, bias=True)
      (C): Linear(in_features=256, out_features=256, bias=True)
      (norm_h): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (norm_e): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (5): GNNLayer(
      (U): Linear(in_features=256, out_features=256, bias=True)
      (V): Linear(in_features=256, out_features=256, bias=True)
      (A): Linear(in_features=256, out_features=256, bias=True)
      (B): Linear(in_features=256, out_features=256, bias=True)
      (C): Linear(in_features=256, out_features=256, bias=True)
      (norm_h): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (norm_e): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (6): GNNLayer(
      (U): Linear(in_features=256, out_features=256, bias=True)
      (V): Linear(in_features=256, out_features=256, bias=True)
      (A): Linear(in_features=256, out_features=256, bias=True)
      (B): Linear(in_features=256, out_features=256, bias=True)
      (C): Linear(in_features=256, out_features=256, bias=True)
      (norm_h): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (norm_e): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (7): GNNLayer(
      (U): Linear(in_features=256, out_features=256, bias=True)
      (V): Linear(in_features=256, out_features=256, bias=True)
      (A): Linear(in_features=256, out_features=256, bias=True)
      (B): Linear(in_features=256, out_features=256, bias=True)
      (C): Linear(in_features=256, out_features=256, bias=True)
      (norm_h): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (norm_e): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (8): GNNLayer(
      (U): Linear(in_features=256, out_features=256, bias=True)
      (V): Linear(in_features=256, out_features=256, bias=True)
      (A): Linear(in_features=256, out_features=256, bias=True)
      (B): Linear(in_features=256, out_features=256, bias=True)
      (C): Linear(in_features=256, out_features=256, bias=True)
      (norm_h): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (norm_e): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (9): GNNLayer(
      (U): Linear(in_features=256, out_features=256, bias=True)
      (V): Linear(in_features=256, out_features=256, bias=True)
      (A): Linear(in_features=256, out_features=256, bias=True)
      (B): Linear(in_features=256, out_features=256, bias=True)
      (C): Linear(in_features=256, out_features=256, bias=True)
      (norm_h): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (norm_e): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (10): GNNLayer(
      (U): Linear(in_features=256, out_features=256, bias=True)
      (V): Linear(in_features=256, out_features=256, bias=True)
      (A): Linear(in_features=256, out_features=256, bias=True)
      (B): Linear(in_features=256, out_features=256, bias=True)
      (C): Linear(in_features=256, out_features=256, bias=True)
      (norm_h): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (norm_e): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (11): GNNLayer(
      (U): Linear(in_features=256, out_features=256, bias=True)
      (V): Linear(in_features=256, out_features=256, bias=True)
      (A): Linear(in_features=256, out_features=256, bias=True)
      (B): Linear(in_features=256, out_features=256, bias=True)
      (C): Linear(in_features=256, out_features=256, bias=True)
      (norm_h): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (norm_e): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
  )
  (time_embed_layers): ModuleList(
    (0): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=256, bias=True)
    )
    (1): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=256, bias=True)
    )
    (2): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=256, bias=True)
    )
    (3): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=256, bias=True)
    )
    (4): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=256, bias=True)
    )
    (5): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=256, bias=True)
    )
    (6): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=256, bias=True)
    )
    (7): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=256, bias=True)
    )
    (8): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=256, bias=True)
    )
    (9): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=256, bias=True)
    )
    (10): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=256, bias=True)
    )
    (11): Sequential(
      (0): ReLU()
      (1): Linear(in_features=128, out_features=256, bias=True)
    )
  )
  (per_layer_out): ModuleList(
    (0): Sequential(
      (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (1): SiLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
    )
    (1): Sequential(
      (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (1): SiLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
    )
    (2): Sequential(
      (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (1): SiLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
    )
    (3): Sequential(
      (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (1): SiLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
    )
    (4): Sequential(
      (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (1): SiLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
    )
    (5): Sequential(
      (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (1): SiLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
    )
    (6): Sequential(
      (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (1): SiLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
    )
    (7): Sequential(
      (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (1): SiLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
    )
    (8): Sequential(
      (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (1): SiLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
    )
    (9): Sequential(
      (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (1): SiLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
    )
    (10): Sequential(
      (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (1): SiLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
    )
    (11): Sequential(
      (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (1): SiLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
    )
  )
)
----------------------------------------------------------------------------------------------------

Loaded "./temp/data/tsp/tsp100_auto_train.txt" with 100000 lines
Loaded "./temp/data/tsp/tsp100_auto_test.txt" with 1000 lines
Loaded "./temp/data/tsp/tsp100_auto_val.txt" with 1000 lines
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/3
Loaded "./temp/data/tsp/tsp100_auto_train.txt" with 100000 lines
Loaded "./temp/data/tsp/tsp100_auto_test.txt" with 1000 lines
Loaded "./temp/data/tsp/tsp100_auto_val.txt" with 1000 lines
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/3
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/3
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 3 processes
----------------------------------------------------------------------------------------------------

Loaded "./temp/data/tsp/tsp100_auto_train.txt" with 100000 lines
Loaded "./temp/data/tsp/tsp100_auto_test.txt" with 1000 lines
Loaded "./temp/data/tsp/tsp100_auto_val.txt" with 1000 lines
Loaded "./temp/data/tsp/tsp100_auto_train.txt" with 100000 lines
Loaded "./temp/data/tsp/tsp100_auto_test.txt" with 1000 lines
Loaded "./temp/data/tsp/tsp100_auto_val.txt" with 1000 lines
Loaded "./temp/data/tsp/tsp100_auto_train.txt" with 100000 lines
Loaded "./temp/data/tsp/tsp100_auto_test.txt" with 1000 lines
Loaded "./temp/data/tsp/tsp100_auto_val.txt" with 1000 lines
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [1,2,3]
/data1/anaconda3/envs/difusco/lib/python3.7/site-packages/torch/nn/parallel/distributed.py:1754: UserWarning: You passed find_unused_parameters=true to DistributedDataParallel, `_set_static_graph` will detect unused parameters automatically, so you do not need to set find_unused_parameters=true, just be sure these unused parameters will not change during training loop while calling `_set_static_graph`.
  "You passed find_unused_parameters=true to DistributedDataParallel, "
Parameters: 5333762
Training steps: 10410

  | Name  | Type       | Params
-------------------------------------
0 | model | GNNEncoder | 5.3 M 
-------------------------------------
5.3 M     Trainable params
0         Non-trainable params
5.3 M     Total params
10.668    Total estimated model params size (MB)
Froze bottom 8 GNN layers for fine-tuning
Built L2SP anchor snapshot for 140 params.
Sanity Checking: 0it [00:00, ?it/s]Validation dataset size: 64
Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:01<00:00,  1.79it/s]                                                                           /data1/anaconda3/envs/difusco/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:241: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 256 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  category=PossibleUserWarning,
/data1/anaconda3/envs/difusco/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:233: UserWarning: You called `self.log('val/2opt_iterations', ...)` in your `validation_step` but the value needs to be floating point. Converting it to torch.float32.
  f"You called `self.log({self.meta.name!r}, ...)` in your `{self.meta.fx}` but the value needs to"
Training: 0it [00:00, ?it/s]Training:   0%|          | 0/1063 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1063 [00:00<?, ?it/s] Validation dataset size: 64
Validation dataset size: 64
/data1/anaconda3/envs/difusco/lib/python3.7/site-packages/torch/nn/parallel/distributed.py:1754: UserWarning: You passed find_unused_parameters=true to DistributedDataParallel, `_set_static_graph` will detect unused parameters automatically, so you do not need to set find_unused_parameters=true, just be sure these unused parameters will not change during training loop while calling `_set_static_graph`.
  "You passed find_unused_parameters=true to DistributedDataParallel, "
/data1/anaconda3/envs/difusco/lib/python3.7/site-packages/torch/nn/parallel/distributed.py:1754: UserWarning: You passed find_unused_parameters=true to DistributedDataParallel, `_set_static_graph` will detect unused parameters automatically, so you do not need to set find_unused_parameters=true, just be sure these unused parameters will not change during training loop while calling `_set_static_graph`.
  "You passed find_unused_parameters=true to DistributedDataParallel, "
Epoch 0:   2%|▏         | 20/1063 [02:34<2:14:09,  7.72s/it]Epoch 0:   2%|▏         | 20/1063 [02:34<2:14:09,  7.72s/it, loss=140, v_num=zw30, train/pref_violate_rate=0.0526, train/pref_pairs=1.000, train/infer_cost=7.810]Epoch 0:   4%|▍         | 40/1063 [05:06<2:10:28,  7.65s/it, loss=140, v_num=zw30, train/pref_violate_rate=0.0526, train/pref_pairs=1.000, train/infer_cost=7.810]Epoch 0:   4%|▍         | 40/1063 [05:06<2:10:28,  7.65s/it, loss=94.8, v_num=zw30, train/pref_violate_rate=0.000, train/pref_pairs=0.000, train/infer_cost=7.780]Epoch 0:   6%|▌         | 60/1063 [07:37<2:07:35,  7.63s/it, loss=94.8, v_num=zw30, train/pref_violate_rate=0.000, train/pref_pairs=0.000, train/infer_cost=7.780]Epoch 0:   6%|▌         | 60/1063 [07:37<2:07:35,  7.63s/it, loss=133, v_num=zw30, train/pref_violate_rate=0.150, train/pref_pairs=3.000, train/infer_cost=7.790] Epoch 0:   8%|▊         | 80/1063 [10:09<2:04:53,  7.62s/it, loss=133, v_num=zw30, train/pref_violate_rate=0.150, train/pref_pairs=3.000, train/infer_cost=7.790]Epoch 0:   8%|▊         | 80/1063 [10:09<2:04:53,  7.62s/it, loss=154, v_num=zw30, train/pref_violate_rate=0.133, train/pref_pairs=2.000, train/infer_cost=7.810]Epoch 0:   9%|▉         | 100/1063 [12:42<2:02:18,  7.62s/it, loss=154, v_num=zw30, train/pref_violate_rate=0.133, train/pref_pairs=2.000, train/infer_cost=7.810]Epoch 0:   9%|▉         | 100/1063 [12:42<2:02:18,  7.62s/it, loss=183, v_num=zw30, train/pref_violate_rate=0.167, train/pref_pairs=4.000, train/infer_cost=7.790]Epoch 0:  11%|█▏        | 120/1063 [15:13<1:59:41,  7.62s/it, loss=183, v_num=zw30, train/pref_violate_rate=0.167, train/pref_pairs=4.000, train/infer_cost=7.790]Epoch 0:  11%|█▏        | 120/1063 [15:13<1:59:41,  7.62s/it, loss=124, v_num=zw30, train/pref_violate_rate=0.000, train/pref_pairs=0.000, train/infer_cost=7.760]Epoch 0:  13%|█▎        | 140/1063 [17:46<1:57:08,  7.61s/it, loss=124, v_num=zw30, train/pref_violate_rate=0.000, train/pref_pairs=0.000, train/infer_cost=7.760]Epoch 0:  13%|█▎        | 140/1063 [17:46<1:57:08,  7.61s/it, loss=102, v_num=zw30, train/pref_violate_rate=0.087, train/pref_pairs=2.000, train/infer_cost=7.800]Epoch 0:  15%|█▌        | 160/1063 [20:18<1:54:34,  7.61s/it, loss=102, v_num=zw30, train/pref_violate_rate=0.087, train/pref_pairs=2.000, train/infer_cost=7.800]Epoch 0:  15%|█▌        | 160/1063 [20:18<1:54:34,  7.61s/it, loss=114, v_num=zw30, train/pref_violate_rate=0.200, train/pref_pairs=4.000, train/infer_cost=7.790]Epoch 0:  17%|█▋        | 180/1063 [22:49<1:51:59,  7.61s/it, loss=114, v_num=zw30, train/pref_violate_rate=0.200, train/pref_pairs=4.000, train/infer_cost=7.790]Epoch 0:  17%|█▋        | 180/1063 [22:49<1:51:59,  7.61s/it, loss=153, v_num=zw30, train/pref_violate_rate=0.176, train/pref_pairs=3.000, train/infer_cost=7.780]Epoch 0:  19%|█▉        | 200/1063 [25:21<1:49:25,  7.61s/it, loss=153, v_num=zw30, train/pref_violate_rate=0.176, train/pref_pairs=3.000, train/infer_cost=7.780]Epoch 0:  19%|█▉        | 200/1063 [25:21<1:49:25,  7.61s/it, loss=119, v_num=zw30, train/pref_violate_rate=0.143, train/pref_pairs=3.000, train/infer_cost=7.800]Epoch 0:  21%|██        | 220/1063 [27:53<1:46:52,  7.61s/it, loss=119, v_num=zw30, train/pref_violate_rate=0.143, train/pref_pairs=3.000, train/infer_cost=7.800]Epoch 0:  21%|██        | 220/1063 [27:53<1:46:52,  7.61s/it, loss=108, v_num=zw30, train/pref_violate_rate=0.087, train/pref_pairs=2.000, train/infer_cost=7.780]Epoch 0:  23%|██▎       | 240/1063 [30:25<1:44:20,  7.61s/it, loss=108, v_num=zw30, train/pref_violate_rate=0.087, train/pref_pairs=2.000, train/infer_cost=7.780]Epoch 0:  23%|██▎       | 240/1063 [30:25<1:44:20,  7.61s/it, loss=110, v_num=zw30, train/pref_violate_rate=0.211, train/pref_pairs=4.000, train/infer_cost=7.830]Epoch 0:  24%|██▍       | 260/1063 [32:57<1:41:47,  7.61s/it, loss=110, v_num=zw30, train/pref_violate_rate=0.211, train/pref_pairs=4.000, train/infer_cost=7.830]Epoch 0:  24%|██▍       | 260/1063 [32:57<1:41:47,  7.61s/it, loss=96.8, v_num=zw30, train/pref_violate_rate=0.250, train/pref_pairs=5.000, train/infer_cost=7.820]Epoch 0:  26%|██▋       | 280/1063 [35:29<1:39:15,  7.61s/it, loss=96.8, v_num=zw30, train/pref_violate_rate=0.250, train/pref_pairs=5.000, train/infer_cost=7.820]Epoch 0:  26%|██▋       | 280/1063 [35:29<1:39:15,  7.61s/it, loss=118, v_num=zw30, train/pref_violate_rate=0.235, train/pref_pairs=4.000, train/infer_cost=7.830] Epoch 0:  28%|██▊       | 300/1063 [38:01<1:36:41,  7.60s/it, loss=118, v_num=zw30, train/pref_violate_rate=0.235, train/pref_pairs=4.000, train/infer_cost=7.830]Epoch 0:  28%|██▊       | 300/1063 [38:01<1:36:41,  7.60s/it, loss=105, v_num=zw30, train/pref_violate_rate=0.278, train/pref_pairs=5.000, train/infer_cost=7.780]Epoch 0:  30%|███       | 320/1063 [40:32<1:34:08,  7.60s/it, loss=105, v_num=zw30, train/pref_violate_rate=0.278, train/pref_pairs=5.000, train/infer_cost=7.780]Epoch 0:  30%|███       | 320/1063 [40:32<1:34:08,  7.60s/it, loss=101, v_num=zw30, train/pref_violate_rate=0.000, train/pref_pairs=0.000, train/infer_cost=7.800]Epoch 0:  32%|███▏      | 340/1063 [43:18<1:32:04,  7.64s/it, loss=101, v_num=zw30, train/pref_violate_rate=0.000, train/pref_pairs=0.000, train/infer_cost=7.800]Epoch 0:  32%|███▏      | 340/1063 [43:18<1:32:04,  7.64s/it, loss=114, v_num=zw30, train/pref_violate_rate=0.143, train/pref_pairs=3.000, train/infer_cost=7.780]Epoch 0:  34%|███▍      | 360/1063 [45:52<1:29:34,  7.65s/it, loss=114, v_num=zw30, train/pref_violate_rate=0.143, train/pref_pairs=3.000, train/infer_cost=7.780]Epoch 0:  34%|███▍      | 360/1063 [45:52<1:29:34,  7.65s/it, loss=153, v_num=zw30, train/pref_violate_rate=0.333, train/pref_pairs=6.000, train/infer_cost=7.800]Epoch 0:  36%|███▌      | 380/1063 [48:29<1:27:09,  7.66s/it, loss=153, v_num=zw30, train/pref_violate_rate=0.333, train/pref_pairs=6.000, train/infer_cost=7.800]Epoch 0:  36%|███▌      | 380/1063 [48:29<1:27:09,  7.66s/it, loss=126, v_num=zw30, train/pref_violate_rate=0.0556, train/pref_pairs=1.000, train/infer_cost=7.810]Epoch 0:  38%|███▊      | 400/1063 [51:01<1:24:34,  7.65s/it, loss=126, v_num=zw30, train/pref_violate_rate=0.0556, train/pref_pairs=1.000, train/infer_cost=7.810]Epoch 0:  38%|███▊      | 400/1063 [51:01<1:24:34,  7.65s/it, loss=60.5, v_num=zw30, train/pref_violate_rate=0.100, train/pref_pairs=2.000, train/infer_cost=7.800]Epoch 0:  40%|███▉      | 420/1063 [53:33<1:22:00,  7.65s/it, loss=60.5, v_num=zw30, train/pref_violate_rate=0.100, train/pref_pairs=2.000, train/infer_cost=7.800]Epoch 0:  40%|███▉      | 420/1063 [53:33<1:22:00,  7.65s/it, loss=145, v_num=zw30, train/pref_violate_rate=0.133, train/pref_pairs=2.000, train/infer_cost=7.810] Epoch 0:  41%|████▏     | 440/1063 [56:09<1:19:31,  7.66s/it, loss=145, v_num=zw30, train/pref_violate_rate=0.133, train/pref_pairs=2.000, train/infer_cost=7.810]Epoch 0:  41%|████▏     | 440/1063 [56:09<1:19:31,  7.66s/it, loss=116, v_num=zw30, train/pref_violate_rate=0.167, train/pref_pairs=3.000, train/infer_cost=7.810]Epoch 0:  43%|████▎     | 460/1063 [59:05<1:17:27,  7.71s/it, loss=116, v_num=zw30, train/pref_violate_rate=0.167, train/pref_pairs=3.000, train/infer_cost=7.810]Epoch 0:  43%|████▎     | 460/1063 [59:05<1:17:27,  7.71s/it, loss=119, v_num=zw30, train/pref_violate_rate=0.130, train/pref_pairs=3.000, train/infer_cost=7.800]Epoch 0:  45%|████▌     | 480/1063 [1:01:40<1:14:54,  7.71s/it, loss=119, v_num=zw30, train/pref_violate_rate=0.130, train/pref_pairs=3.000, train/infer_cost=7.800]Epoch 0:  45%|████▌     | 480/1063 [1:01:40<1:14:54,  7.71s/it, loss=99.4, v_num=zw30, train/pref_violate_rate=0.167, train/pref_pairs=3.000, train/infer_cost=7.770]/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
Epoch 0:  47%|████▋     | 500/1063 [1:04:55<1:13:05,  7.79s/it, loss=99.4, v_num=zw30, train/pref_violate_rate=0.167, train/pref_pairs=3.000, train/infer_cost=7.770]Epoch 0:  47%|████▋     | 500/1063 [1:04:55<1:13:05,  7.79s/it, loss=117, v_num=zw30, train/pref_violate_rate=0.250, train/pref_pairs=5.000, train/infer_cost=7.810] Epoch 0:  49%|████▉     | 520/1063 [1:07:54<1:10:54,  7.84s/it, loss=117, v_num=zw30, train/pref_violate_rate=0.250, train/pref_pairs=5.000, train/infer_cost=7.810]Epoch 0:  49%|████▉     | 520/1063 [1:07:54<1:10:54,  7.84s/it, loss=91, v_num=zw30, train/pref_violate_rate=0.0556, train/pref_pairs=1.000, train/infer_cost=7.740]Epoch 0:  51%|█████     | 540/1063 [1:10:26<1:08:13,  7.83s/it, loss=91, v_num=zw30, train/pref_violate_rate=0.0556, train/pref_pairs=1.000, train/infer_cost=7.740]Epoch 0:  51%|█████     | 540/1063 [1:10:26<1:08:13,  7.83s/it, loss=91, v_num=zw30, train/pref_violate_rate=0.158, train/pref_pairs=3.000, train/infer_cost=7.780] Epoch 0:  53%|█████▎    | 560/1063 [1:12:58<1:05:32,  7.82s/it, loss=91, v_num=zw30, train/pref_violate_rate=0.158, train/pref_pairs=3.000, train/infer_cost=7.780]Epoch 0:  53%|█████▎    | 560/1063 [1:12:58<1:05:32,  7.82s/it, loss=123, v_num=zw30, train/pref_violate_rate=0.250, train/pref_pairs=4.000, train/infer_cost=7.770]/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
Epoch 0:  55%|█████▍    | 580/1063 [1:15:31<1:02:53,  7.81s/it, loss=123, v_num=zw30, train/pref_violate_rate=0.250, train/pref_pairs=4.000, train/infer_cost=7.770]Epoch 0:  55%|█████▍    | 580/1063 [1:15:31<1:02:53,  7.81s/it, loss=80.3, v_num=zw30, train/pref_violate_rate=0.105, train/pref_pairs=2.000, train/infer_cost=7.790]Epoch 0:  56%|█████▋    | 600/1063 [1:18:03<1:00:14,  7.81s/it, loss=80.3, v_num=zw30, train/pref_violate_rate=0.105, train/pref_pairs=2.000, train/infer_cost=7.790]Epoch 0:  56%|█████▋    | 600/1063 [1:18:03<1:00:14,  7.81s/it, loss=90.5, v_num=zw30, train/pref_violate_rate=0.250, train/pref_pairs=4.000, train/infer_cost=7.820]Epoch 0:  58%|█████▊    | 620/1063 [1:20:35<57:35,  7.80s/it, loss=90.5, v_num=zw30, train/pref_violate_rate=0.250, train/pref_pairs=4.000, train/infer_cost=7.820]  Epoch 0:  58%|█████▊    | 620/1063 [1:20:35<57:35,  7.80s/it, loss=116, v_num=zw30, train/pref_violate_rate=0.0588, train/pref_pairs=1.000, train/infer_cost=7.810]Epoch 0:  60%|██████    | 640/1063 [1:23:07<54:56,  7.79s/it, loss=116, v_num=zw30, train/pref_violate_rate=0.0588, train/pref_pairs=1.000, train/infer_cost=7.810]Epoch 0:  60%|██████    | 640/1063 [1:23:07<54:56,  7.79s/it, loss=65.6, v_num=zw30, train/pref_violate_rate=0.227, train/pref_pairs=5.000, train/infer_cost=7.780]Epoch 0:  62%|██████▏   | 660/1063 [1:25:39<52:18,  7.79s/it, loss=65.6, v_num=zw30, train/pref_violate_rate=0.227, train/pref_pairs=5.000, train/infer_cost=7.780]Epoch 0:  62%|██████▏   | 660/1063 [1:25:39<52:18,  7.79s/it, loss=83.2, v_num=zw30, train/pref_violate_rate=0.200, train/pref_pairs=4.000, train/infer_cost=7.780]Epoch 0:  64%|██████▍   | 680/1063 [1:28:14<49:41,  7.79s/it, loss=83.2, v_num=zw30, train/pref_violate_rate=0.200, train/pref_pairs=4.000, train/infer_cost=7.780]Epoch 0:  64%|██████▍   | 680/1063 [1:28:14<49:41,  7.79s/it, loss=71, v_num=zw30, train/pref_violate_rate=0.190, train/pref_pairs=4.000, train/infer_cost=7.830]  Epoch 0:  66%|██████▌   | 700/1063 [1:30:47<47:04,  7.78s/it, loss=71, v_num=zw30, train/pref_violate_rate=0.190, train/pref_pairs=4.000, train/infer_cost=7.830]Epoch 0:  66%|██████▌   | 700/1063 [1:30:47<47:04,  7.78s/it, loss=87.7, v_num=zw30, train/pref_violate_rate=0.0526, train/pref_pairs=1.000, train/infer_cost=7.780]Epoch 0:  68%|██████▊   | 720/1063 [1:33:19<44:27,  7.78s/it, loss=87.7, v_num=zw30, train/pref_violate_rate=0.0526, train/pref_pairs=1.000, train/infer_cost=7.780]Epoch 0:  68%|██████▊   | 720/1063 [1:33:19<44:27,  7.78s/it, loss=84.1, v_num=zw30, train/pref_violate_rate=0.200, train/pref_pairs=4.000, train/infer_cost=7.770] Epoch 0:  70%|██████▉   | 740/1063 [1:35:55<41:52,  7.78s/it, loss=84.1, v_num=zw30, train/pref_violate_rate=0.200, train/pref_pairs=4.000, train/infer_cost=7.770]Epoch 0:  70%|██████▉   | 740/1063 [1:35:55<41:52,  7.78s/it, loss=78.8, v_num=zw30, train/pref_violate_rate=0.118, train/pref_pairs=2.000, train/infer_cost=7.810]Epoch 0:  71%|███████▏  | 760/1063 [1:38:30<39:16,  7.78s/it, loss=78.8, v_num=zw30, train/pref_violate_rate=0.118, train/pref_pairs=2.000, train/infer_cost=7.810]Epoch 0:  71%|███████▏  | 760/1063 [1:38:30<39:16,  7.78s/it, loss=91.7, v_num=zw30, train/pref_violate_rate=0.176, train/pref_pairs=3.000, train/infer_cost=7.780]Epoch 0:  73%|███████▎  | 780/1063 [1:41:10<36:42,  7.78s/it, loss=91.7, v_num=zw30, train/pref_violate_rate=0.176, train/pref_pairs=3.000, train/infer_cost=7.780]Epoch 0:  73%|███████▎  | 780/1063 [1:41:10<36:42,  7.78s/it, loss=82.1, v_num=zw30, train/pref_violate_rate=0.0526, train/pref_pairs=1.000, train/infer_cost=7.790]Epoch 0:  75%|███████▌  | 800/1063 [1:43:51<34:08,  7.79s/it, loss=82.1, v_num=zw30, train/pref_violate_rate=0.0526, train/pref_pairs=1.000, train/infer_cost=7.790]Epoch 0:  75%|███████▌  | 800/1063 [1:43:51<34:08,  7.79s/it, loss=68.1, v_num=zw30, train/pref_violate_rate=0.136, train/pref_pairs=3.000, train/infer_cost=7.780] Epoch 0:  77%|███████▋  | 820/1063 [1:46:35<31:35,  7.80s/it, loss=68.1, v_num=zw30, train/pref_violate_rate=0.136, train/pref_pairs=3.000, train/infer_cost=7.780]Epoch 0:  77%|███████▋  | 820/1063 [1:46:35<31:35,  7.80s/it, loss=58.3, v_num=zw30, train/pref_violate_rate=0.100, train/pref_pairs=2.000, train/infer_cost=7.780]Epoch 0:  79%|███████▉  | 840/1063 [1:49:11<28:59,  7.80s/it, loss=58.3, v_num=zw30, train/pref_violate_rate=0.100, train/pref_pairs=2.000, train/infer_cost=7.780]Epoch 0:  79%|███████▉  | 840/1063 [1:49:11<28:59,  7.80s/it, loss=58.7, v_num=zw30, train/pref_violate_rate=0.250, train/pref_pairs=5.000, train/infer_cost=7.820]Epoch 0:  81%|████████  | 860/1063 [1:51:44<26:22,  7.80s/it, loss=58.7, v_num=zw30, train/pref_violate_rate=0.250, train/pref_pairs=5.000, train/infer_cost=7.820]Epoch 0:  81%|████████  | 860/1063 [1:51:44<26:22,  7.80s/it, loss=55.9, v_num=zw30, train/pref_violate_rate=0.375, train/pref_pairs=9.000, train/infer_cost=7.750]Epoch 0:  83%|████████▎ | 880/1063 [1:54:17<23:46,  7.79s/it, loss=55.9, v_num=zw30, train/pref_violate_rate=0.375, train/pref_pairs=9.000, train/infer_cost=7.750]Epoch 0:  83%|████████▎ | 880/1063 [1:54:17<23:46,  7.79s/it, loss=51.6, v_num=zw30, train/pref_violate_rate=0.421, train/pref_pairs=8.000, train/infer_cost=7.880]Epoch 0:  85%|████████▍ | 900/1063 [1:57:08<21:12,  7.81s/it, loss=51.6, v_num=zw30, train/pref_violate_rate=0.421, train/pref_pairs=8.000, train/infer_cost=7.880]Epoch 0:  85%|████████▍ | 900/1063 [1:57:08<21:12,  7.81s/it, loss=66.6, v_num=zw30, train/pref_violate_rate=0.381, train/pref_pairs=8.000, train/infer_cost=7.830]Epoch 0:  87%|████████▋ | 920/1063 [1:59:46<18:36,  7.81s/it, loss=66.6, v_num=zw30, train/pref_violate_rate=0.381, train/pref_pairs=8.000, train/infer_cost=7.830]Epoch 0:  87%|████████▋ | 920/1063 [1:59:46<18:36,  7.81s/it, loss=68.5, v_num=zw30, train/pref_violate_rate=0.211, train/pref_pairs=4.000, train/infer_cost=7.820]Epoch 0:  88%|████████▊ | 940/1063 [2:02:27<16:01,  7.82s/it, loss=68.5, v_num=zw30, train/pref_violate_rate=0.211, train/pref_pairs=4.000, train/infer_cost=7.820]Epoch 0:  88%|████████▊ | 940/1063 [2:02:27<16:01,  7.82s/it, loss=62.9, v_num=zw30, train/pref_violate_rate=0.381, train/pref_pairs=8.000, train/infer_cost=7.790]Epoch 0:  90%|█████████ | 960/1063 [2:05:04<13:25,  7.82s/it, loss=62.9, v_num=zw30, train/pref_violate_rate=0.381, train/pref_pairs=8.000, train/infer_cost=7.790]Epoch 0:  90%|█████████ | 960/1063 [2:05:04<13:25,  7.82s/it, loss=62.3, v_num=zw30, train/pref_violate_rate=0.250, train/pref_pairs=6.000, train/infer_cost=7.820]Epoch 0:  92%|█████████▏| 980/1063 [2:07:39<10:48,  7.82s/it, loss=62.3, v_num=zw30, train/pref_violate_rate=0.250, train/pref_pairs=6.000, train/infer_cost=7.820]Epoch 0:  92%|█████████▏| 980/1063 [2:07:39<10:48,  7.82s/it, loss=57, v_num=zw30, train/pref_violate_rate=0.231, train/pref_pairs=6.000, train/infer_cost=7.770]  Epoch 0:  94%|█████████▍| 1000/1063 [2:10:14<08:12,  7.81s/it, loss=57, v_num=zw30, train/pref_violate_rate=0.231, train/pref_pairs=6.000, train/infer_cost=7.770]Epoch 0:  94%|█████████▍| 1000/1063 [2:10:14<08:12,  7.81s/it, loss=45.2, v_num=zw30, train/pref_violate_rate=0.261, train/pref_pairs=6.000, train/infer_cost=7.810]Epoch 0:  96%|█████████▌| 1020/1063 [2:12:50<05:35,  7.81s/it, loss=45.2, v_num=zw30, train/pref_violate_rate=0.261, train/pref_pairs=6.000, train/infer_cost=7.810]Epoch 0:  96%|█████████▌| 1020/1063 [2:12:50<05:35,  7.81s/it, loss=54.2, v_num=zw30, train/pref_violate_rate=0.308, train/pref_pairs=8.000, train/infer_cost=7.800]Epoch 0:  98%|█████████▊| 1040/1063 [2:15:26<02:59,  7.81s/it, loss=54.2, v_num=zw30, train/pref_violate_rate=0.308, train/pref_pairs=8.000, train/infer_cost=7.800]Epoch 0:  98%|█████████▊| 1040/1063 [2:15:26<02:59,  7.81s/it, loss=46.4, v_num=zw30, train/pref_violate_rate=0.280, train/pref_pairs=7.000, train/infer_cost=7.810]/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,
/data1/gushengda/PbDifusco/difusco/pl_tsp_model.py:560: RuntimeWarning: No preference pairs were formed in this batch (all graphs degenerated to a single unique tour).
  RuntimeWarning,

Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/22 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/22 [00:00<?, ?it/s][AEpoch 0: 100%|█████████▉| 1060/1063 [2:15:50<00:23,  7.69s/it, loss=46.4, v_num=zw30, train/pref_violate_rate=0.280, train/pref_pairs=7.000, train/infer_cost=7.810]
Validation DataLoader 0:  91%|█████████ | 20/22 [00:17<00:01,  1.13it/s][A
Validation DataLoader 0: 100%|██████████| 22/22 [00:19<00:00,  1.13it/s][AEpoch 0: 100%|██████████| 1063/1063 [2:15:53<00:00,  7.67s/it, loss=46.4, v_num=zw30, train/pref_violate_rate=0.280, train/pref_pairs=7.000, train/infer_cost=7.810]Epoch 0: 100%|██████████| 1063/1063 [2:15:53<00:00,  7.67s/it, loss=46.1, v_num=zw30, train/pref_violate_rate=0.321, train/pref_pairs=9.000, train/infer_cost=7.800]
                                                                        [AEpoch 0: 100%|██████████| 1063/1063 [2:15:53<00:00,  7.67s/it, loss=46.1, v_num=zw30, train/pref_violate_rate=0.321, train/pref_pairs=9.000, train/infer_cost=7.800]Epoch 0:   0%|          | 0/1063 [00:00<?, ?it/s, loss=46.1, v_num=zw30, train/pref_violate_rate=0.321, train/pref_pairs=9.000, train/infer_cost=7.800]             Epoch 1:   0%|          | 0/1063 [00:00<?, ?it/s, loss=46.1, v_num=zw30, train/pref_violate_rate=0.321, train/pref_pairs=9.000, train/infer_cost=7.800]Epoch 1:   2%|▏         | 20/1063 [02:35<2:15:32,  7.80s/it, loss=46.1, v_num=zw30, train/pref_violate_rate=0.321, train/pref_pairs=9.000, train/infer_cost=7.800]Epoch 1:   2%|▏         | 20/1063 [02:35<2:15:32,  7.80s/it, loss=52.4, v_num=zw30, train/pref_violate_rate=0.263, train/pref_pairs=5.000, train/infer_cost=7.830]Epoch 1:   4%|▍         | 40/1063 [05:12<2:13:18,  7.82s/it, loss=52.4, v_num=zw30, train/pref_violate_rate=0.263, train/pref_pairs=5.000, train/infer_cost=7.830]Epoch 1:   4%|▍         | 40/1063 [05:12<2:13:18,  7.82s/it, loss=37.3, v_num=zw30, train/pref_violate_rate=0.308, train/pref_pairs=8.000, train/infer_cost=7.830]Epoch 1:   6%|▌         | 60/1063 [07:49<2:10:56,  7.83s/it, loss=37.3, v_num=zw30, train/pref_violate_rate=0.308, train/pref_pairs=8.000, train/infer_cost=7.830]Epoch 1:   6%|▌         | 60/1063 [07:49<2:10:56,  7.83s/it, loss=41.2, v_num=zw30, train/pref_violate_rate=0.346, train/pref_pairs=9.000, train/infer_cost=7.830]Epoch 1:   8%|▊         | 80/1063 [10:28<2:08:36,  7.85s/it, loss=41.2, v_num=zw30, train/pref_violate_rate=0.346, train/pref_pairs=9.000, train/infer_cost=7.830]Epoch 1:   8%|▊         | 80/1063 [10:28<2:08:36,  7.85s/it, loss=44.9, v_num=zw30, train/pref_violate_rate=0.269, train/pref_pairs=7.000, train/infer_cost=7.810]Epoch 1:   9%|▉         | 100/1063 [13:12<2:07:15,  7.93s/it, loss=44.9, v_num=zw30, train/pref_violate_rate=0.269, train/pref_pairs=7.000, train/infer_cost=7.810]Epoch 1:   9%|▉         | 100/1063 [13:12<2:07:15,  7.93s/it, loss=48.1, v_num=zw30, train/pref_violate_rate=0.423, train/pref_pairs=11.00, train/infer_cost=7.820]Epoch 1:  11%|█▏        | 120/1063 [15:50<2:04:32,  7.92s/it, loss=48.1, v_num=zw30, train/pref_violate_rate=0.423, train/pref_pairs=11.00, train/infer_cost=7.820]Epoch 1:  11%|█▏        | 120/1063 [15:50<2:04:32,  7.92s/it, loss=44.5, v_num=zw30, train/pref_violate_rate=0.154, train/pref_pairs=4.000, train/infer_cost=7.800]Epoch 1:  13%|█▎        | 140/1063 [18:29<2:01:54,  7.92s/it, loss=44.5, v_num=zw30, train/pref_violate_rate=0.154, train/pref_pairs=4.000, train/infer_cost=7.800]Epoch 1:  13%|█▎        | 140/1063 [18:29<2:01:54,  7.92s/it, loss=42.7, v_num=zw30, train/pref_violate_rate=0.357, train/pref_pairs=10.00, train/infer_cost=7.830]Epoch 1:  15%|█▌        | 160/1063 [21:08<1:59:17,  7.93s/it, loss=42.7, v_num=zw30, train/pref_violate_rate=0.357, train/pref_pairs=10.00, train/infer_cost=7.830]Epoch 1:  15%|█▌        | 160/1063 [21:08<1:59:17,  7.93s/it, loss=29.8, v_num=zw30, train/pref_violate_rate=0.393, train/pref_pairs=11.00, train/infer_cost=7.840]Epoch 1:  17%|█▋        | 180/1063 [24:19<1:59:20,  8.11s/it, loss=29.8, v_num=zw30, train/pref_violate_rate=0.393, train/pref_pairs=11.00, train/infer_cost=7.840]Epoch 1:  17%|█▋        | 180/1063 [24:19<1:59:20,  8.11s/it, loss=36.6, v_num=zw30, train/pref_violate_rate=0.448, train/pref_pairs=13.00, train/infer_cost=7.840]Epoch 1:  19%|█▉        | 200/1063 [26:58<1:56:25,  8.09s/it, loss=36.6, v_num=zw30, train/pref_violate_rate=0.448, train/pref_pairs=13.00, train/infer_cost=7.840]Epoch 1:  19%|█▉        | 200/1063 [26:58<1:56:25,  8.09s/it, loss=28.5, v_num=zw30, train/pref_violate_rate=0.290, train/pref_pairs=9.000, train/infer_cost=7.890]Epoch 1:  21%|██        | 220/1063 [29:38<1:53:36,  8.09s/it, loss=28.5, v_num=zw30, train/pref_violate_rate=0.290, train/pref_pairs=9.000, train/infer_cost=7.890]Epoch 1:  21%|██        | 220/1063 [29:38<1:53:36,  8.09s/it, loss=29.7, v_num=zw30, train/pref_violate_rate=0.219, train/pref_pairs=7.000, train/infer_cost=7.920]Epoch 1:  23%|██▎       | 240/1063 [32:19<1:50:49,  8.08s/it, loss=29.7, v_num=zw30, train/pref_violate_rate=0.219, train/pref_pairs=7.000, train/infer_cost=7.920]Epoch 1:  23%|██▎       | 240/1063 [32:19<1:50:49,  8.08s/it, loss=36.8, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=15.00, train/infer_cost=7.860]Epoch 1:  24%|██▍       | 260/1063 [34:59<1:48:04,  8.08s/it, loss=36.8, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=15.00, train/infer_cost=7.860]Epoch 1:  24%|██▍       | 260/1063 [34:59<1:48:04,  8.08s/it, loss=38, v_num=zw30, train/pref_violate_rate=0.379, train/pref_pairs=11.00, train/infer_cost=7.860]  Epoch 1:  26%|██▋       | 280/1063 [37:40<1:45:20,  8.07s/it, loss=38, v_num=zw30, train/pref_violate_rate=0.379, train/pref_pairs=11.00, train/infer_cost=7.860]Epoch 1:  26%|██▋       | 280/1063 [37:40<1:45:20,  8.07s/it, loss=30.6, v_num=zw30, train/pref_violate_rate=0.448, train/pref_pairs=13.00, train/infer_cost=7.890]Epoch 1:  28%|██▊       | 300/1063 [40:21<1:42:37,  8.07s/it, loss=30.6, v_num=zw30, train/pref_violate_rate=0.448, train/pref_pairs=13.00, train/infer_cost=7.890]Epoch 1:  28%|██▊       | 300/1063 [40:21<1:42:37,  8.07s/it, loss=28.3, v_num=zw30, train/pref_violate_rate=0.323, train/pref_pairs=10.00, train/infer_cost=7.940]Epoch 1:  30%|███       | 320/1063 [43:09<1:40:11,  8.09s/it, loss=28.3, v_num=zw30, train/pref_violate_rate=0.323, train/pref_pairs=10.00, train/infer_cost=7.940]Epoch 1:  30%|███       | 320/1063 [43:09<1:40:11,  8.09s/it, loss=29.6, v_num=zw30, train/pref_violate_rate=0.517, train/pref_pairs=15.00, train/infer_cost=7.860]Epoch 1:  32%|███▏      | 340/1063 [45:56<1:37:40,  8.11s/it, loss=29.6, v_num=zw30, train/pref_violate_rate=0.517, train/pref_pairs=15.00, train/infer_cost=7.860]Epoch 1:  32%|███▏      | 340/1063 [45:56<1:37:40,  8.11s/it, loss=28.1, v_num=zw30, train/pref_violate_rate=0.375, train/pref_pairs=12.00, train/infer_cost=7.870]Epoch 1:  34%|███▍      | 360/1063 [48:44<1:35:11,  8.12s/it, loss=28.1, v_num=zw30, train/pref_violate_rate=0.375, train/pref_pairs=12.00, train/infer_cost=7.870]Epoch 1:  34%|███▍      | 360/1063 [48:44<1:35:11,  8.12s/it, loss=25.6, v_num=zw30, train/pref_violate_rate=0.419, train/pref_pairs=13.00, train/infer_cost=7.860]Epoch 1:  36%|███▌      | 380/1063 [51:33<1:32:40,  8.14s/it, loss=25.6, v_num=zw30, train/pref_violate_rate=0.419, train/pref_pairs=13.00, train/infer_cost=7.860]Epoch 1:  36%|███▌      | 380/1063 [51:33<1:32:40,  8.14s/it, loss=27, v_num=zw30, train/pref_violate_rate=0.452, train/pref_pairs=14.00, train/infer_cost=7.890]  Epoch 1:  38%|███▊      | 400/1063 [54:56<1:31:03,  8.24s/it, loss=27, v_num=zw30, train/pref_violate_rate=0.452, train/pref_pairs=14.00, train/infer_cost=7.890]Epoch 1:  38%|███▊      | 400/1063 [54:56<1:31:03,  8.24s/it, loss=26.2, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=7.870]Epoch 1:  40%|███▉      | 420/1063 [57:57<1:28:43,  8.28s/it, loss=26.2, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=7.870]Epoch 1:  40%|███▉      | 420/1063 [57:57<1:28:43,  8.28s/it, loss=24.8, v_num=zw30, train/pref_violate_rate=0.419, train/pref_pairs=13.00, train/infer_cost=7.920]Epoch 1:  41%|████▏     | 440/1063 [1:00:45<1:26:01,  8.29s/it, loss=24.8, v_num=zw30, train/pref_violate_rate=0.419, train/pref_pairs=13.00, train/infer_cost=7.920]Epoch 1:  41%|████▏     | 440/1063 [1:00:45<1:26:01,  8.29s/it, loss=25.4, v_num=zw30, train/pref_violate_rate=0.452, train/pref_pairs=14.00, train/infer_cost=7.880]Epoch 1:  43%|████▎     | 460/1063 [1:03:45<1:23:35,  8.32s/it, loss=25.4, v_num=zw30, train/pref_violate_rate=0.452, train/pref_pairs=14.00, train/infer_cost=7.880]Epoch 1:  43%|████▎     | 460/1063 [1:03:45<1:23:35,  8.32s/it, loss=25.3, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=7.940]Epoch 1:  45%|████▌     | 480/1063 [1:06:29<1:20:45,  8.31s/it, loss=25.3, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=7.940]Epoch 1:  45%|████▌     | 480/1063 [1:06:29<1:20:45,  8.31s/it, loss=25.6, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=7.870]Epoch 1:  47%|████▋     | 500/1063 [1:09:15<1:17:58,  8.31s/it, loss=25.6, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=7.870]Epoch 1:  47%|████▋     | 500/1063 [1:09:15<1:17:58,  8.31s/it, loss=25.7, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=7.900]Epoch 1:  49%|████▉     | 520/1063 [1:12:32<1:15:44,  8.37s/it, loss=25.7, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=7.900]Epoch 1:  49%|████▉     | 520/1063 [1:12:32<1:15:44,  8.37s/it, loss=22.1, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=7.920]Epoch 1:  51%|█████     | 540/1063 [1:15:29<1:13:06,  8.39s/it, loss=22.1, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=7.920]Epoch 1:  51%|█████     | 540/1063 [1:15:29<1:13:06,  8.39s/it, loss=20.3, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=7.900]Epoch 1:  53%|█████▎    | 560/1063 [1:18:17<1:10:19,  8.39s/it, loss=20.3, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=7.900]Epoch 1:  53%|█████▎    | 560/1063 [1:18:17<1:10:19,  8.39s/it, loss=21.2, v_num=zw30, train/pref_violate_rate=0.516, train/pref_pairs=16.00, train/infer_cost=7.950]Epoch 1:  55%|█████▍    | 580/1063 [1:21:09<1:07:34,  8.40s/it, loss=21.2, v_num=zw30, train/pref_violate_rate=0.516, train/pref_pairs=16.00, train/infer_cost=7.950]Epoch 1:  55%|█████▍    | 580/1063 [1:21:09<1:07:34,  8.40s/it, loss=20, v_num=zw30, train/pref_violate_rate=0.355, train/pref_pairs=11.00, train/infer_cost=7.950]  Epoch 1:  56%|█████▋    | 600/1063 [1:24:04<1:04:52,  8.41s/it, loss=20, v_num=zw30, train/pref_violate_rate=0.355, train/pref_pairs=11.00, train/infer_cost=7.950]Epoch 1:  56%|█████▋    | 600/1063 [1:24:04<1:04:52,  8.41s/it, loss=20.4, v_num=zw30, train/pref_violate_rate=0.452, train/pref_pairs=14.00, train/infer_cost=7.920]Epoch 1:  58%|█████▊    | 620/1063 [1:26:56<1:02:07,  8.41s/it, loss=20.4, v_num=zw30, train/pref_violate_rate=0.452, train/pref_pairs=14.00, train/infer_cost=7.920]Epoch 1:  58%|█████▊    | 620/1063 [1:26:56<1:02:07,  8.41s/it, loss=19.1, v_num=zw30, train/pref_violate_rate=0.594, train/pref_pairs=19.00, train/infer_cost=7.970]Epoch 1:  60%|██████    | 640/1063 [1:30:13<59:37,  8.46s/it, loss=19.1, v_num=zw30, train/pref_violate_rate=0.594, train/pref_pairs=19.00, train/infer_cost=7.970]  Epoch 1:  60%|██████    | 640/1063 [1:30:13<59:37,  8.46s/it, loss=19.4, v_num=zw30, train/pref_violate_rate=0.625, train/pref_pairs=20.00, train/infer_cost=7.930]Epoch 1:  62%|██████▏   | 660/1063 [1:33:07<56:51,  8.47s/it, loss=19.4, v_num=zw30, train/pref_violate_rate=0.625, train/pref_pairs=20.00, train/infer_cost=7.930]Epoch 1:  62%|██████▏   | 660/1063 [1:33:07<56:51,  8.47s/it, loss=18.2, v_num=zw30, train/pref_violate_rate=0.194, train/pref_pairs=6.000, train/infer_cost=7.960]Epoch 1:  64%|██████▍   | 680/1063 [1:35:56<54:02,  8.47s/it, loss=18.2, v_num=zw30, train/pref_violate_rate=0.194, train/pref_pairs=6.000, train/infer_cost=7.960]Epoch 1:  64%|██████▍   | 680/1063 [1:35:56<54:02,  8.47s/it, loss=19.9, v_num=zw30, train/pref_violate_rate=0.344, train/pref_pairs=11.00, train/infer_cost=7.980]Epoch 1:  66%|██████▌   | 700/1063 [1:38:45<51:12,  8.46s/it, loss=19.9, v_num=zw30, train/pref_violate_rate=0.344, train/pref_pairs=11.00, train/infer_cost=7.980]Epoch 1:  66%|██████▌   | 700/1063 [1:38:45<51:12,  8.46s/it, loss=15.4, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=7.960]Epoch 1:  68%|██████▊   | 720/1063 [1:41:36<48:24,  8.47s/it, loss=15.4, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=7.960]Epoch 1:  68%|██████▊   | 720/1063 [1:41:36<48:24,  8.47s/it, loss=17.3, v_num=zw30, train/pref_violate_rate=0.312, train/pref_pairs=10.00, train/infer_cost=7.950]Epoch 1:  70%|██████▉   | 740/1063 [1:44:27<45:35,  8.47s/it, loss=17.3, v_num=zw30, train/pref_violate_rate=0.312, train/pref_pairs=10.00, train/infer_cost=7.950]Epoch 1:  70%|██████▉   | 740/1063 [1:44:27<45:35,  8.47s/it, loss=15.1, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=7.990]Epoch 1:  71%|███████▏  | 760/1063 [1:47:34<42:53,  8.49s/it, loss=15.1, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=7.990]Epoch 1:  71%|███████▏  | 760/1063 [1:47:34<42:53,  8.49s/it, loss=15.2, v_num=zw30, train/pref_violate_rate=0.594, train/pref_pairs=19.00, train/infer_cost=7.980]Epoch 1:  73%|███████▎  | 780/1063 [1:50:41<40:09,  8.51s/it, loss=15.2, v_num=zw30, train/pref_violate_rate=0.594, train/pref_pairs=19.00, train/infer_cost=7.980]Epoch 1:  73%|███████▎  | 780/1063 [1:50:41<40:09,  8.51s/it, loss=14.1, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.010]Epoch 1:  75%|███████▌  | 800/1063 [1:53:28<37:18,  8.51s/it, loss=14.1, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.010]Epoch 1:  75%|███████▌  | 800/1063 [1:53:28<37:18,  8.51s/it, loss=15.6, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=7.940]Epoch 1:  77%|███████▋  | 820/1063 [1:56:22<34:29,  8.52s/it, loss=15.6, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=7.940]Epoch 1:  77%|███████▋  | 820/1063 [1:56:22<34:29,  8.52s/it, loss=14.8, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=7.940]Epoch 1:  79%|███████▉  | 840/1063 [1:59:10<31:38,  8.51s/it, loss=14.8, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=7.940]Epoch 1:  79%|███████▉  | 840/1063 [1:59:10<31:38,  8.51s/it, loss=14.1, v_num=zw30, train/pref_violate_rate=0.250, train/pref_pairs=8.000, train/infer_cost=7.980]Epoch 1:  81%|████████  | 860/1063 [2:01:54<28:46,  8.51s/it, loss=14.1, v_num=zw30, train/pref_violate_rate=0.250, train/pref_pairs=8.000, train/infer_cost=7.980]Epoch 1:  81%|████████  | 860/1063 [2:01:54<28:46,  8.51s/it, loss=13.2, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.040]Epoch 1:  83%|████████▎ | 880/1063 [2:04:39<25:55,  8.50s/it, loss=13.2, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.040]Epoch 1:  83%|████████▎ | 880/1063 [2:04:39<25:55,  8.50s/it, loss=13.2, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.050]Epoch 1:  85%|████████▍ | 900/1063 [2:07:27<23:04,  8.50s/it, loss=13.2, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.050]Epoch 1:  85%|████████▍ | 900/1063 [2:07:27<23:04,  8.50s/it, loss=12.8, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=7.980]Epoch 1:  87%|████████▋ | 920/1063 [2:10:12<20:14,  8.49s/it, loss=12.8, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=7.980]Epoch 1:  87%|████████▋ | 920/1063 [2:10:12<20:14,  8.49s/it, loss=12, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.050]  Epoch 1:  88%|████████▊ | 940/1063 [2:12:56<17:23,  8.49s/it, loss=12, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.050]Epoch 1:  88%|████████▊ | 940/1063 [2:12:56<17:23,  8.49s/it, loss=12.8, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=7.980]Epoch 1:  90%|█████████ | 960/1063 [2:15:40<14:33,  8.48s/it, loss=12.8, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=7.980]Epoch 1:  90%|█████████ | 960/1063 [2:15:40<14:33,  8.48s/it, loss=10.8, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.050]Epoch 1:  92%|█████████▏| 980/1063 [2:18:24<11:43,  8.47s/it, loss=10.8, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.050]Epoch 1:  92%|█████████▏| 980/1063 [2:18:24<11:43,  8.47s/it, loss=12.4, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.070]Epoch 1:  94%|█████████▍| 1000/1063 [2:21:08<08:53,  8.47s/it, loss=12.4, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.070]Epoch 1:  94%|█████████▍| 1000/1063 [2:21:08<08:53,  8.47s/it, loss=11.7, v_num=zw30, train/pref_violate_rate=0.594, train/pref_pairs=19.00, train/infer_cost=8.000]Epoch 1:  96%|█████████▌| 1020/1063 [2:23:53<06:03,  8.46s/it, loss=11.7, v_num=zw30, train/pref_violate_rate=0.594, train/pref_pairs=19.00, train/infer_cost=8.000]Epoch 1:  96%|█████████▌| 1020/1063 [2:23:53<06:03,  8.46s/it, loss=9.63, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=7.980]Epoch 1:  98%|█████████▊| 1040/1063 [2:26:58<03:15,  8.48s/it, loss=9.63, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=7.980]Epoch 1:  98%|█████████▊| 1040/1063 [2:26:58<03:15,  8.48s/it, loss=10.4, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.020]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/22 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/22 [00:00<?, ?it/s][AEpoch 1: 100%|█████████▉| 1060/1063 [2:27:47<00:25,  8.37s/it, loss=10.4, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.020]
Validation DataLoader 0:  91%|█████████ | 20/22 [00:39<00:03,  1.98s/it][A
Validation DataLoader 0: 100%|██████████| 22/22 [00:41<00:00,  1.89s/it][AEpoch 1: 100%|██████████| 1063/1063 [2:27:50<00:00,  8.34s/it, loss=10.4, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.020]Epoch 1: 100%|██████████| 1063/1063 [2:27:50<00:00,  8.34s/it, loss=10.6, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.060]
                                                                        [AEpoch 1: 100%|██████████| 1063/1063 [2:27:50<00:00,  8.34s/it, loss=10.6, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.060]Epoch 1:   0%|          | 0/1063 [00:00<?, ?it/s, loss=10.6, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.060]             Epoch 2:   0%|          | 0/1063 [00:00<?, ?it/s, loss=10.6, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.060]Epoch 2:   2%|▏         | 20/1063 [02:50<2:28:18,  8.53s/it, loss=10.6, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.060]Epoch 2:   2%|▏         | 20/1063 [02:50<2:28:18,  8.53s/it, loss=9.25, v_num=zw30, train/pref_violate_rate=0.625, train/pref_pairs=20.00, train/infer_cost=8.050]Epoch 2:   4%|▍         | 40/1063 [05:34<2:22:35,  8.36s/it, loss=9.25, v_num=zw30, train/pref_violate_rate=0.625, train/pref_pairs=20.00, train/infer_cost=8.050]Epoch 2:   4%|▍         | 40/1063 [05:34<2:22:35,  8.36s/it, loss=9.74, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.040]Epoch 2:   6%|▌         | 60/1063 [08:18<2:18:52,  8.31s/it, loss=9.74, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.040]Epoch 2:   6%|▌         | 60/1063 [08:18<2:18:52,  8.31s/it, loss=8.66, v_num=zw30, train/pref_violate_rate=0.375, train/pref_pairs=12.00, train/infer_cost=8.120]Epoch 2:   8%|▊         | 80/1063 [11:08<2:16:52,  8.35s/it, loss=8.66, v_num=zw30, train/pref_violate_rate=0.375, train/pref_pairs=12.00, train/infer_cost=8.120]Epoch 2:   8%|▊         | 80/1063 [11:08<2:16:52,  8.35s/it, loss=8.38, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.040]Epoch 2:   9%|▉         | 100/1063 [13:53<2:13:43,  8.33s/it, loss=8.38, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.040]Epoch 2:   9%|▉         | 100/1063 [13:53<2:13:43,  8.33s/it, loss=8.22, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.090]Epoch 2:  11%|█▏        | 120/1063 [16:40<2:11:00,  8.34s/it, loss=8.22, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.090]Epoch 2:  11%|█▏        | 120/1063 [16:40<2:11:00,  8.34s/it, loss=9.43, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.070]Epoch 2:  13%|█▎        | 140/1063 [19:24<2:07:54,  8.32s/it, loss=9.43, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.070]Epoch 2:  13%|█▎        | 140/1063 [19:24<2:07:54,  8.32s/it, loss=7.64, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.080]Epoch 2:  15%|█▌        | 160/1063 [22:15<2:05:38,  8.35s/it, loss=7.64, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.080]Epoch 2:  15%|█▌        | 160/1063 [22:15<2:05:38,  8.35s/it, loss=7.4, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.070] Epoch 2:  17%|█▋        | 180/1063 [25:00<2:02:38,  8.33s/it, loss=7.4, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.070]Epoch 2:  17%|█▋        | 180/1063 [25:00<2:02:38,  8.33s/it, loss=6.47, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.070]Epoch 2:  19%|█▉        | 200/1063 [27:52<2:00:15,  8.36s/it, loss=6.47, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.070]Epoch 2:  19%|█▉        | 200/1063 [27:52<2:00:15,  8.36s/it, loss=8.42, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.050]Epoch 2:  21%|██        | 220/1063 [30:38<1:57:25,  8.36s/it, loss=8.42, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.050]Epoch 2:  21%|██        | 220/1063 [30:38<1:57:25,  8.36s/it, loss=7.29, v_num=zw30, train/pref_violate_rate=0.625, train/pref_pairs=20.00, train/infer_cost=8.100]Epoch 2:  23%|██▎       | 240/1063 [33:28<1:54:46,  8.37s/it, loss=7.29, v_num=zw30, train/pref_violate_rate=0.625, train/pref_pairs=20.00, train/infer_cost=8.100]Epoch 2:  23%|██▎       | 240/1063 [33:28<1:54:46,  8.37s/it, loss=6.38, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.110]Epoch 2:  24%|██▍       | 260/1063 [36:14<1:51:54,  8.36s/it, loss=6.38, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.110]Epoch 2:  24%|██▍       | 260/1063 [36:14<1:51:54,  8.36s/it, loss=6.44, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.130]Epoch 2:  26%|██▋       | 280/1063 [38:59<1:49:02,  8.36s/it, loss=6.44, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.130]Epoch 2:  26%|██▋       | 280/1063 [38:59<1:49:02,  8.36s/it, loss=6.46, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.160]Epoch 2:  28%|██▊       | 300/1063 [41:47<1:46:16,  8.36s/it, loss=6.46, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.160]Epoch 2:  28%|██▊       | 300/1063 [41:47<1:46:16,  8.36s/it, loss=5.99, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.100]Epoch 2:  30%|███       | 320/1063 [44:32<1:43:26,  8.35s/it, loss=5.99, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.100]Epoch 2:  30%|███       | 320/1063 [44:32<1:43:26,  8.35s/it, loss=5.13, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.140]Epoch 2:  32%|███▏      | 340/1063 [47:16<1:40:32,  8.34s/it, loss=5.13, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.140]Epoch 2:  32%|███▏      | 340/1063 [47:16<1:40:32,  8.34s/it, loss=5.64, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.180]Epoch 2:  34%|███▍      | 360/1063 [50:23<1:38:24,  8.40s/it, loss=5.64, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.180]Epoch 2:  34%|███▍      | 360/1063 [50:23<1:38:24,  8.40s/it, loss=5.62, v_num=zw30, train/pref_violate_rate=0.281, train/pref_pairs=9.000, train/infer_cost=8.110]Epoch 2:  36%|███▌      | 380/1063 [53:25<1:36:02,  8.44s/it, loss=5.62, v_num=zw30, train/pref_violate_rate=0.281, train/pref_pairs=9.000, train/infer_cost=8.110]Epoch 2:  36%|███▌      | 380/1063 [53:25<1:36:02,  8.44s/it, loss=5.65, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.150]Epoch 2:  38%|███▊      | 400/1063 [56:10<1:33:06,  8.43s/it, loss=5.65, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.150]Epoch 2:  38%|███▊      | 400/1063 [56:10<1:33:06,  8.43s/it, loss=5.14, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.100]Epoch 2:  40%|███▉      | 420/1063 [58:54<1:30:11,  8.42s/it, loss=5.14, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.100]Epoch 2:  40%|███▉      | 420/1063 [58:54<1:30:11,  8.42s/it, loss=4.9, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.120] Epoch 2:  41%|████▏     | 440/1063 [1:01:45<1:27:26,  8.42s/it, loss=4.9, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.120]Epoch 2:  41%|████▏     | 440/1063 [1:01:45<1:27:26,  8.42s/it, loss=4.58, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.120]Epoch 2:  43%|████▎     | 460/1063 [1:04:31<1:24:34,  8.42s/it, loss=4.58, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.120]Epoch 2:  43%|████▎     | 460/1063 [1:04:31<1:24:34,  8.42s/it, loss=4.76, v_num=zw30, train/pref_violate_rate=0.625, train/pref_pairs=20.00, train/infer_cost=8.080]Epoch 2:  45%|████▌     | 480/1063 [1:07:17<1:21:43,  8.41s/it, loss=4.76, v_num=zw30, train/pref_violate_rate=0.625, train/pref_pairs=20.00, train/infer_cost=8.080]Epoch 2:  45%|████▌     | 480/1063 [1:07:17<1:21:43,  8.41s/it, loss=4.46, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.160]Epoch 2:  47%|████▋     | 500/1063 [1:10:01<1:18:51,  8.40s/it, loss=4.46, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.160]Epoch 2:  47%|████▋     | 500/1063 [1:10:01<1:18:51,  8.40s/it, loss=4.42, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.170]Epoch 2:  49%|████▉     | 520/1063 [1:12:54<1:16:08,  8.41s/it, loss=4.42, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.170]Epoch 2:  49%|████▉     | 520/1063 [1:12:54<1:16:08,  8.41s/it, loss=4.47, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.090]Epoch 2:  51%|█████     | 540/1063 [1:15:39<1:13:16,  8.41s/it, loss=4.47, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.090]Epoch 2:  51%|█████     | 540/1063 [1:15:39<1:13:16,  8.41s/it, loss=3.99, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.100]Epoch 2:  53%|█████▎    | 560/1063 [1:18:31<1:10:31,  8.41s/it, loss=3.99, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.100]Epoch 2:  53%|█████▎    | 560/1063 [1:18:31<1:10:31,  8.41s/it, loss=3.81, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.130]Epoch 2:  55%|█████▍    | 580/1063 [1:21:16<1:07:41,  8.41s/it, loss=3.81, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.130]Epoch 2:  55%|█████▍    | 580/1063 [1:21:16<1:07:41,  8.41s/it, loss=3.7, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.140] Epoch 2:  56%|█████▋    | 600/1063 [1:24:05<1:04:53,  8.41s/it, loss=3.7, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.140]Epoch 2:  56%|█████▋    | 600/1063 [1:24:05<1:04:53,  8.41s/it, loss=3.77, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.260]Epoch 2:  58%|█████▊    | 620/1063 [1:26:49<1:02:02,  8.40s/it, loss=3.77, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.260]Epoch 2:  58%|█████▊    | 620/1063 [1:26:49<1:02:02,  8.40s/it, loss=3.84, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.130]Epoch 2:  60%|██████    | 640/1063 [1:29:35<59:12,  8.40s/it, loss=3.84, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.130]  Epoch 2:  60%|██████    | 640/1063 [1:29:35<59:12,  8.40s/it, loss=3.43, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.170]Epoch 2:  62%|██████▏   | 660/1063 [1:32:20<56:23,  8.39s/it, loss=3.43, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.170]Epoch 2:  62%|██████▏   | 660/1063 [1:32:20<56:23,  8.39s/it, loss=3.11, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.180]Epoch 2:  64%|██████▍   | 680/1063 [1:35:10<53:36,  8.40s/it, loss=3.11, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.180]Epoch 2:  64%|██████▍   | 680/1063 [1:35:10<53:36,  8.40s/it, loss=3.48, v_num=zw30, train/pref_violate_rate=0.625, train/pref_pairs=20.00, train/infer_cost=8.160]Epoch 2:  66%|██████▌   | 700/1063 [1:37:55<50:47,  8.39s/it, loss=3.48, v_num=zw30, train/pref_violate_rate=0.625, train/pref_pairs=20.00, train/infer_cost=8.160]Epoch 2:  66%|██████▌   | 700/1063 [1:37:55<50:47,  8.39s/it, loss=3.2, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.190] Epoch 2:  68%|██████▊   | 720/1063 [1:40:40<47:57,  8.39s/it, loss=3.2, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.190]Epoch 2:  68%|██████▊   | 720/1063 [1:40:40<47:57,  8.39s/it, loss=3.22, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.200]Epoch 2:  70%|██████▉   | 740/1063 [1:43:24<45:08,  8.38s/it, loss=3.22, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.200]Epoch 2:  70%|██████▉   | 740/1063 [1:43:24<45:08,  8.38s/it, loss=3.16, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.170]Epoch 2:  71%|███████▏  | 760/1063 [1:46:57<42:38,  8.44s/it, loss=3.16, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.170]Epoch 2:  71%|███████▏  | 760/1063 [1:46:57<42:38,  8.44s/it, loss=3.13, v_num=zw30, train/pref_violate_rate=0.375, train/pref_pairs=12.00, train/infer_cost=8.170]Epoch 2:  73%|███████▎  | 780/1063 [1:49:43<39:48,  8.44s/it, loss=3.13, v_num=zw30, train/pref_violate_rate=0.375, train/pref_pairs=12.00, train/infer_cost=8.170]Epoch 2:  73%|███████▎  | 780/1063 [1:49:43<39:48,  8.44s/it, loss=2.98, v_num=zw30, train/pref_violate_rate=0.375, train/pref_pairs=12.00, train/infer_cost=8.110]Epoch 2:  75%|███████▌  | 800/1063 [1:52:28<36:58,  8.44s/it, loss=2.98, v_num=zw30, train/pref_violate_rate=0.375, train/pref_pairs=12.00, train/infer_cost=8.110]Epoch 2:  75%|███████▌  | 800/1063 [1:52:28<36:58,  8.44s/it, loss=2.92, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.130]Epoch 2:  77%|███████▋  | 820/1063 [1:55:23<34:11,  8.44s/it, loss=2.92, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.130]Epoch 2:  77%|███████▋  | 820/1063 [1:55:23<34:11,  8.44s/it, loss=2.8, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.200] Epoch 2:  79%|███████▉  | 840/1063 [1:58:09<31:22,  8.44s/it, loss=2.8, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.200]Epoch 2:  79%|███████▉  | 840/1063 [1:58:09<31:22,  8.44s/it, loss=2.85, v_num=zw30, train/pref_violate_rate=0.656, train/pref_pairs=21.00, train/infer_cost=8.160]Epoch 2:  81%|████████  | 860/1063 [2:00:56<28:32,  8.44s/it, loss=2.85, v_num=zw30, train/pref_violate_rate=0.656, train/pref_pairs=21.00, train/infer_cost=8.160]Epoch 2:  81%|████████  | 860/1063 [2:00:56<28:32,  8.44s/it, loss=2.79, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.200]Epoch 2:  83%|████████▎ | 880/1063 [2:03:41<25:43,  8.43s/it, loss=2.79, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.200]Epoch 2:  83%|████████▎ | 880/1063 [2:03:41<25:43,  8.43s/it, loss=2.62, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.200]Epoch 2:  85%|████████▍ | 900/1063 [2:06:35<22:55,  8.44s/it, loss=2.62, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.200]Epoch 2:  85%|████████▍ | 900/1063 [2:06:35<22:55,  8.44s/it, loss=2.71, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.150]Epoch 2:  87%|████████▋ | 920/1063 [2:09:21<20:06,  8.44s/it, loss=2.71, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.150]Epoch 2:  87%|████████▋ | 920/1063 [2:09:21<20:06,  8.44s/it, loss=2.79, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.180]Epoch 2:  88%|████████▊ | 940/1063 [2:12:14<17:18,  8.44s/it, loss=2.79, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.180]Epoch 2:  88%|████████▊ | 940/1063 [2:12:14<17:18,  8.44s/it, loss=2.51, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.160]Epoch 2:  90%|█████████ | 960/1063 [2:14:59<14:29,  8.44s/it, loss=2.51, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.160]Epoch 2:  90%|█████████ | 960/1063 [2:14:59<14:29,  8.44s/it, loss=2.59, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.190]Epoch 2:  92%|█████████▏| 980/1063 [2:17:48<11:40,  8.44s/it, loss=2.59, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.190]Epoch 2:  92%|█████████▏| 980/1063 [2:17:48<11:40,  8.44s/it, loss=2.38, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.270]Epoch 2:  94%|█████████▍| 1000/1063 [2:20:33<08:51,  8.43s/it, loss=2.38, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.270]Epoch 2:  94%|█████████▍| 1000/1063 [2:20:33<08:51,  8.43s/it, loss=2.27, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.160]Epoch 2:  96%|█████████▌| 1020/1063 [2:23:18<06:02,  8.43s/it, loss=2.27, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.160]Epoch 2:  96%|█████████▌| 1020/1063 [2:23:18<06:02,  8.43s/it, loss=2.28, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.210]Epoch 2:  98%|█████████▊| 1040/1063 [2:26:07<03:13,  8.43s/it, loss=2.28, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.210]Epoch 2:  98%|█████████▊| 1040/1063 [2:26:07<03:13,  8.43s/it, loss=2.25, v_num=zw30, train/pref_violate_rate=0.594, train/pref_pairs=19.00, train/infer_cost=8.190]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/22 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/22 [00:00<?, ?it/s][AEpoch 2: 100%|█████████▉| 1060/1063 [2:26:33<00:24,  8.30s/it, loss=2.25, v_num=zw30, train/pref_violate_rate=0.594, train/pref_pairs=19.00, train/infer_cost=8.190]
Validation DataLoader 0:  91%|█████████ | 20/22 [00:18<00:01,  1.09it/s][A
Validation DataLoader 0: 100%|██████████| 22/22 [00:20<00:00,  1.08it/s][AEpoch 2: 100%|██████████| 1063/1063 [2:26:36<00:00,  8.27s/it, loss=2.25, v_num=zw30, train/pref_violate_rate=0.594, train/pref_pairs=19.00, train/infer_cost=8.190]Epoch 2: 100%|██████████| 1063/1063 [2:26:36<00:00,  8.27s/it, loss=2.16, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.190]
                                                                        [AEpoch 2: 100%|██████████| 1063/1063 [2:26:36<00:00,  8.27s/it, loss=2.16, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.190]Epoch 2:   0%|          | 0/1063 [00:00<?, ?it/s, loss=2.16, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.190]             Epoch 3:   0%|          | 0/1063 [00:00<?, ?it/s, loss=2.16, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.190]Epoch 3:   2%|▏         | 20/1063 [02:45<2:24:12,  8.30s/it, loss=2.16, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.190]Epoch 3:   2%|▏         | 20/1063 [02:45<2:24:12,  8.30s/it, loss=2.36, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.200]Epoch 3:   4%|▍         | 40/1063 [05:30<2:20:50,  8.26s/it, loss=2.36, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.200]Epoch 3:   4%|▍         | 40/1063 [05:30<2:20:50,  8.26s/it, loss=2.34, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.160]Epoch 3:   6%|▌         | 60/1063 [08:15<2:17:56,  8.25s/it, loss=2.34, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.160]Epoch 3:   6%|▌         | 60/1063 [08:15<2:17:56,  8.25s/it, loss=2.59, v_num=zw30, train/pref_violate_rate=0.656, train/pref_pairs=21.00, train/infer_cost=8.170]Epoch 3:   8%|▊         | 80/1063 [10:59<2:15:05,  8.25s/it, loss=2.59, v_num=zw30, train/pref_violate_rate=0.656, train/pref_pairs=21.00, train/infer_cost=8.170]Epoch 3:   8%|▊         | 80/1063 [10:59<2:15:05,  8.25s/it, loss=2.11, v_num=zw30, train/pref_violate_rate=0.625, train/pref_pairs=20.00, train/infer_cost=8.180]Epoch 3:   9%|▉         | 100/1063 [13:44<2:12:17,  8.24s/it, loss=2.11, v_num=zw30, train/pref_violate_rate=0.625, train/pref_pairs=20.00, train/infer_cost=8.180]Epoch 3:   9%|▉         | 100/1063 [13:44<2:12:17,  8.24s/it, loss=2.27, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.240]Epoch 3:  11%|█▏        | 120/1063 [16:28<2:09:28,  8.24s/it, loss=2.27, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.240]Epoch 3:  11%|█▏        | 120/1063 [16:28<2:09:28,  8.24s/it, loss=2.2, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.220] Epoch 3:  13%|█▎        | 140/1063 [19:13<2:06:41,  8.24s/it, loss=2.2, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.220]Epoch 3:  13%|█▎        | 140/1063 [19:13<2:06:41,  8.24s/it, loss=2.08, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.230]Epoch 3:  15%|█▌        | 160/1063 [21:57<2:03:55,  8.23s/it, loss=2.08, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.230]Epoch 3:  15%|█▌        | 160/1063 [21:57<2:03:55,  8.23s/it, loss=2.1, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.220] Epoch 3:  17%|█▋        | 180/1063 [24:42<2:01:11,  8.24s/it, loss=2.1, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.220]Epoch 3:  17%|█▋        | 180/1063 [24:42<2:01:11,  8.24s/it, loss=2.16, v_num=zw30, train/pref_violate_rate=0.594, train/pref_pairs=19.00, train/infer_cost=8.130]Epoch 3:  19%|█▉        | 200/1063 [27:26<1:58:25,  8.23s/it, loss=2.16, v_num=zw30, train/pref_violate_rate=0.594, train/pref_pairs=19.00, train/infer_cost=8.130]Epoch 3:  19%|█▉        | 200/1063 [27:26<1:58:25,  8.23s/it, loss=1.98, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.170]Epoch 3:  21%|██        | 220/1063 [30:11<1:55:41,  8.23s/it, loss=1.98, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.170]Epoch 3:  21%|██        | 220/1063 [30:11<1:55:41,  8.23s/it, loss=1.9, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.210] Epoch 3:  23%|██▎       | 240/1063 [33:36<1:55:16,  8.40s/it, loss=1.9, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.210]Epoch 3:  23%|██▎       | 240/1063 [33:36<1:55:16,  8.40s/it, loss=1.91, v_num=zw30, train/pref_violate_rate=0.250, train/pref_pairs=8.000, train/infer_cost=8.260]Epoch 3:  24%|██▍       | 260/1063 [36:23<1:52:23,  8.40s/it, loss=1.91, v_num=zw30, train/pref_violate_rate=0.250, train/pref_pairs=8.000, train/infer_cost=8.260]Epoch 3:  24%|██▍       | 260/1063 [36:23<1:52:23,  8.40s/it, loss=2.06, v_num=zw30, train/pref_violate_rate=0.375, train/pref_pairs=12.00, train/infer_cost=8.130]Epoch 3:  26%|██▋       | 280/1063 [39:07<1:49:25,  8.39s/it, loss=2.06, v_num=zw30, train/pref_violate_rate=0.375, train/pref_pairs=12.00, train/infer_cost=8.130]Epoch 3:  26%|██▋       | 280/1063 [39:07<1:49:25,  8.39s/it, loss=2, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.170]   Epoch 3:  28%|██▊       | 300/1063 [41:52<1:46:30,  8.38s/it, loss=2, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.170]Epoch 3:  28%|██▊       | 300/1063 [41:52<1:46:30,  8.38s/it, loss=1.89, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.180]Epoch 3:  30%|███       | 320/1063 [44:46<1:43:58,  8.40s/it, loss=1.89, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.180]Epoch 3:  30%|███       | 320/1063 [44:46<1:43:58,  8.40s/it, loss=1.7, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.170] Epoch 3:  32%|███▏      | 340/1063 [47:31<1:41:04,  8.39s/it, loss=1.7, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.170]Epoch 3:  32%|███▏      | 340/1063 [47:31<1:41:04,  8.39s/it, loss=1.71, v_num=zw30, train/pref_violate_rate=0.625, train/pref_pairs=20.00, train/infer_cost=8.240]Epoch 3:  34%|███▍      | 360/1063 [50:33<1:38:43,  8.43s/it, loss=1.71, v_num=zw30, train/pref_violate_rate=0.625, train/pref_pairs=20.00, train/infer_cost=8.240]Epoch 3:  34%|███▍      | 360/1063 [50:33<1:38:43,  8.43s/it, loss=1.9, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.320] Epoch 3:  36%|███▌      | 380/1063 [53:19<1:35:51,  8.42s/it, loss=1.9, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.320]Epoch 3:  36%|███▌      | 380/1063 [53:19<1:35:51,  8.42s/it, loss=1.79, v_num=zw30, train/pref_violate_rate=0.625, train/pref_pairs=20.00, train/infer_cost=8.250]Epoch 3:  38%|███▊      | 400/1063 [56:04<1:32:56,  8.41s/it, loss=1.79, v_num=zw30, train/pref_violate_rate=0.625, train/pref_pairs=20.00, train/infer_cost=8.250]Epoch 3:  38%|███▊      | 400/1063 [56:04<1:32:56,  8.41s/it, loss=1.72, v_num=zw30, train/pref_violate_rate=0.625, train/pref_pairs=20.00, train/infer_cost=8.170]Epoch 3:  40%|███▉      | 420/1063 [58:48<1:30:02,  8.40s/it, loss=1.72, v_num=zw30, train/pref_violate_rate=0.625, train/pref_pairs=20.00, train/infer_cost=8.170]Epoch 3:  40%|███▉      | 420/1063 [58:48<1:30:02,  8.40s/it, loss=1.72, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.130]Epoch 3:  41%|████▏     | 440/1063 [1:01:40<1:27:20,  8.41s/it, loss=1.72, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.130]Epoch 3:  41%|████▏     | 440/1063 [1:01:40<1:27:20,  8.41s/it, loss=1.7, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.260] Epoch 3:  43%|████▎     | 460/1063 [1:04:27<1:24:29,  8.41s/it, loss=1.7, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.260]Epoch 3:  43%|████▎     | 460/1063 [1:04:27<1:24:29,  8.41s/it, loss=1.55, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.270]Epoch 3:  45%|████▌     | 480/1063 [1:07:18<1:21:45,  8.41s/it, loss=1.55, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.270]Epoch 3:  45%|████▌     | 480/1063 [1:07:18<1:21:45,  8.41s/it, loss=1.72, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.200]Epoch 3:  47%|████▋     | 500/1063 [1:10:04<1:18:54,  8.41s/it, loss=1.72, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.200]Epoch 3:  47%|████▋     | 500/1063 [1:10:04<1:18:54,  8.41s/it, loss=1.64, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.210]Epoch 3:  49%|████▉     | 520/1063 [1:12:54<1:16:07,  8.41s/it, loss=1.64, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.210]Epoch 3:  49%|████▉     | 520/1063 [1:12:54<1:16:07,  8.41s/it, loss=1.59, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.230]Epoch 3:  51%|█████     | 540/1063 [1:15:38<1:13:15,  8.40s/it, loss=1.59, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.230]Epoch 3:  51%|█████     | 540/1063 [1:15:38<1:13:15,  8.40s/it, loss=1.69, v_num=zw30, train/pref_violate_rate=0.688, train/pref_pairs=22.00, train/infer_cost=8.250]Epoch 3:  53%|█████▎    | 560/1063 [1:18:26<1:10:27,  8.40s/it, loss=1.69, v_num=zw30, train/pref_violate_rate=0.688, train/pref_pairs=22.00, train/infer_cost=8.250]Epoch 3:  53%|█████▎    | 560/1063 [1:18:26<1:10:27,  8.40s/it, loss=1.63, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.230]Epoch 3:  55%|█████▍    | 580/1063 [1:21:11<1:07:36,  8.40s/it, loss=1.63, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.230]Epoch 3:  55%|█████▍    | 580/1063 [1:21:11<1:07:36,  8.40s/it, loss=1.65, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.290]Epoch 3:  56%|█████▋    | 600/1063 [1:24:00<1:04:49,  8.40s/it, loss=1.65, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.290]Epoch 3:  56%|█████▋    | 600/1063 [1:24:00<1:04:49,  8.40s/it, loss=1.49, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.270]Epoch 3:  58%|█████▊    | 620/1063 [1:26:46<1:02:00,  8.40s/it, loss=1.49, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.270]Epoch 3:  58%|█████▊    | 620/1063 [1:26:46<1:02:00,  8.40s/it, loss=1.57, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.210]Epoch 3:  60%|██████    | 640/1063 [1:29:31<59:10,  8.39s/it, loss=1.57, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.210]  Epoch 3:  60%|██████    | 640/1063 [1:29:31<59:10,  8.39s/it, loss=1.45, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.220]Epoch 3:  62%|██████▏   | 660/1063 [1:32:15<56:20,  8.39s/it, loss=1.45, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.220]Epoch 3:  62%|██████▏   | 660/1063 [1:32:15<56:20,  8.39s/it, loss=1.6, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.220] Epoch 3:  64%|██████▍   | 680/1063 [1:35:00<53:30,  8.38s/it, loss=1.6, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.220]Epoch 3:  64%|██████▍   | 680/1063 [1:35:00<53:30,  8.38s/it, loss=1.46, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.250]Epoch 3:  66%|██████▌   | 700/1063 [1:38:29<51:04,  8.44s/it, loss=1.46, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.250]Epoch 3:  66%|██████▌   | 700/1063 [1:38:29<51:04,  8.44s/it, loss=1.57, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.240]Epoch 3:  68%|██████▊   | 720/1063 [1:41:15<48:14,  8.44s/it, loss=1.57, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.240]Epoch 3:  68%|██████▊   | 720/1063 [1:41:15<48:14,  8.44s/it, loss=1.5, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.190] Epoch 3:  70%|██████▉   | 740/1063 [1:43:59<45:23,  8.43s/it, loss=1.5, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.190]Epoch 3:  70%|██████▉   | 740/1063 [1:43:59<45:23,  8.43s/it, loss=1.51, v_num=zw30, train/pref_violate_rate=0.625, train/pref_pairs=20.00, train/infer_cost=8.270]Epoch 3:  71%|███████▏  | 760/1063 [1:46:44<42:33,  8.43s/it, loss=1.51, v_num=zw30, train/pref_violate_rate=0.625, train/pref_pairs=20.00, train/infer_cost=8.270]Epoch 3:  71%|███████▏  | 760/1063 [1:46:44<42:33,  8.43s/it, loss=1.54, v_num=zw30, train/pref_violate_rate=0.344, train/pref_pairs=11.00, train/infer_cost=8.280]Epoch 3:  73%|███████▎  | 780/1063 [1:49:40<39:47,  8.44s/it, loss=1.54, v_num=zw30, train/pref_violate_rate=0.344, train/pref_pairs=11.00, train/infer_cost=8.280]Epoch 3:  73%|███████▎  | 780/1063 [1:49:40<39:47,  8.44s/it, loss=1.39, v_num=zw30, train/pref_violate_rate=0.344, train/pref_pairs=11.00, train/infer_cost=8.260]Epoch 3:  75%|███████▌  | 800/1063 [1:52:26<36:57,  8.43s/it, loss=1.39, v_num=zw30, train/pref_violate_rate=0.344, train/pref_pairs=11.00, train/infer_cost=8.260]Epoch 3:  75%|███████▌  | 800/1063 [1:52:26<36:57,  8.43s/it, loss=1.54, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.290]Epoch 3:  77%|███████▋  | 820/1063 [1:55:22<34:11,  8.44s/it, loss=1.54, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.290]Epoch 3:  77%|███████▋  | 820/1063 [1:55:22<34:11,  8.44s/it, loss=1.48, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.290]Epoch 3:  79%|███████▉  | 840/1063 [1:58:07<31:21,  8.44s/it, loss=1.48, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.290]Epoch 3:  79%|███████▉  | 840/1063 [1:58:07<31:21,  8.44s/it, loss=1.45, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.330]Epoch 3:  81%|████████  | 860/1063 [2:00:52<28:31,  8.43s/it, loss=1.45, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.330]Epoch 3:  81%|████████  | 860/1063 [2:00:52<28:31,  8.43s/it, loss=1.37, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.250]Epoch 3:  83%|████████▎ | 880/1063 [2:03:43<25:43,  8.44s/it, loss=1.37, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.250]Epoch 3:  83%|████████▎ | 880/1063 [2:03:43<25:43,  8.44s/it, loss=1.52, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.230]Epoch 3:  85%|████████▍ | 900/1063 [2:06:29<22:54,  8.43s/it, loss=1.52, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.230]Epoch 3:  85%|████████▍ | 900/1063 [2:06:29<22:54,  8.43s/it, loss=1.34, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.220]Epoch 3:  87%|████████▋ | 920/1063 [2:09:16<20:05,  8.43s/it, loss=1.34, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.220]Epoch 3:  87%|████████▋ | 920/1063 [2:09:16<20:05,  8.43s/it, loss=1.35, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.190]Epoch 3:  88%|████████▊ | 940/1063 [2:12:03<17:16,  8.43s/it, loss=1.35, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.190]Epoch 3:  88%|████████▊ | 940/1063 [2:12:03<17:16,  8.43s/it, loss=1.37, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.150]Epoch 3:  90%|█████████ | 960/1063 [2:14:53<14:28,  8.43s/it, loss=1.37, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.150]Epoch 3:  90%|█████████ | 960/1063 [2:14:53<14:28,  8.43s/it, loss=1.37, v_num=zw30, train/pref_violate_rate=0.594, train/pref_pairs=19.00, train/infer_cost=8.250]Epoch 3:  92%|█████████▏| 980/1063 [2:17:38<11:39,  8.43s/it, loss=1.37, v_num=zw30, train/pref_violate_rate=0.594, train/pref_pairs=19.00, train/infer_cost=8.250]Epoch 3:  92%|█████████▏| 980/1063 [2:17:38<11:39,  8.43s/it, loss=1.28, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.220]Epoch 3:  94%|█████████▍| 1000/1063 [2:20:23<08:50,  8.42s/it, loss=1.28, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.220]Epoch 3:  94%|█████████▍| 1000/1063 [2:20:23<08:50,  8.42s/it, loss=1.35, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.190]Epoch 3:  96%|█████████▌| 1020/1063 [2:23:07<06:02,  8.42s/it, loss=1.35, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.190]Epoch 3:  96%|█████████▌| 1020/1063 [2:23:07<06:02,  8.42s/it, loss=1.34, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.240]Epoch 3:  98%|█████████▊| 1040/1063 [2:25:56<03:13,  8.42s/it, loss=1.34, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.240]Epoch 3:  98%|█████████▊| 1040/1063 [2:25:56<03:13,  8.42s/it, loss=1.28, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.300]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/22 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/22 [00:00<?, ?it/s][AEpoch 3: 100%|█████████▉| 1060/1063 [2:26:22<00:24,  8.29s/it, loss=1.28, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.300]
Validation DataLoader 0:  91%|█████████ | 20/22 [00:18<00:01,  1.07it/s][A
Validation DataLoader 0: 100%|██████████| 22/22 [00:20<00:00,  1.07it/s][AEpoch 3: 100%|██████████| 1063/1063 [2:26:25<00:00,  8.26s/it, loss=1.28, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.300]Epoch 3: 100%|██████████| 1063/1063 [2:26:25<00:00,  8.27s/it, loss=1.29, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.240]
                                                                        [AEpoch 3: 100%|██████████| 1063/1063 [2:26:25<00:00,  8.27s/it, loss=1.29, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.240]Epoch 3:   0%|          | 0/1063 [00:00<?, ?it/s, loss=1.29, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.240]             Epoch 4:   0%|          | 0/1063 [00:00<?, ?it/s, loss=1.29, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.240]Epoch 4:   2%|▏         | 20/1063 [02:45<2:23:50,  8.27s/it, loss=1.29, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.240]Epoch 4:   2%|▏         | 20/1063 [02:45<2:23:50,  8.27s/it, loss=1.35, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.170]Epoch 4:   4%|▍         | 40/1063 [05:34<2:22:30,  8.36s/it, loss=1.35, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.170]Epoch 4:   4%|▍         | 40/1063 [05:34<2:22:30,  8.36s/it, loss=1.23, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.270]Epoch 4:   6%|▌         | 60/1063 [08:53<2:28:42,  8.90s/it, loss=1.23, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.270]Epoch 4:   6%|▌         | 60/1063 [08:53<2:28:42,  8.90s/it, loss=1.27, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.240]Epoch 4:   8%|▊         | 80/1063 [11:39<2:23:17,  8.75s/it, loss=1.27, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.240]Epoch 4:   8%|▊         | 80/1063 [11:39<2:23:17,  8.75s/it, loss=1.27, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.290]Epoch 4:   9%|▉         | 100/1063 [14:24<2:18:40,  8.64s/it, loss=1.27, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.290]Epoch 4:   9%|▉         | 100/1063 [14:24<2:18:40,  8.64s/it, loss=1.32, v_num=zw30, train/pref_violate_rate=0.312, train/pref_pairs=10.00, train/infer_cost=8.260]Epoch 4:  11%|█▏        | 120/1063 [17:08<2:14:38,  8.57s/it, loss=1.32, v_num=zw30, train/pref_violate_rate=0.312, train/pref_pairs=10.00, train/infer_cost=8.260]Epoch 4:  11%|█▏        | 120/1063 [17:08<2:14:38,  8.57s/it, loss=1.28, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.240]Epoch 4:  13%|█▎        | 140/1063 [20:01<2:12:04,  8.59s/it, loss=1.28, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.240]Epoch 4:  13%|█▎        | 140/1063 [20:01<2:12:04,  8.59s/it, loss=1.25, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.240]Epoch 4:  15%|█▌        | 160/1063 [22:48<2:08:45,  8.56s/it, loss=1.25, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.240]Epoch 4:  15%|█▌        | 160/1063 [22:48<2:08:45,  8.56s/it, loss=1.25, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.250]Epoch 4:  17%|█▋        | 180/1063 [25:38<2:05:45,  8.55s/it, loss=1.25, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.250]Epoch 4:  17%|█▋        | 180/1063 [25:38<2:05:45,  8.55s/it, loss=1.2, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.290] Epoch 4:  19%|█▉        | 200/1063 [28:22<2:02:26,  8.51s/it, loss=1.2, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.290]Epoch 4:  19%|█▉        | 200/1063 [28:22<2:02:26,  8.51s/it, loss=1.18, v_num=zw30, train/pref_violate_rate=0.375, train/pref_pairs=12.00, train/infer_cost=8.270]Epoch 4:  21%|██        | 220/1063 [31:06<1:59:13,  8.49s/it, loss=1.18, v_num=zw30, train/pref_violate_rate=0.375, train/pref_pairs=12.00, train/infer_cost=8.270]Epoch 4:  21%|██        | 220/1063 [31:06<1:59:13,  8.49s/it, loss=1.29, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.250]Epoch 4:  23%|██▎       | 240/1063 [34:02<1:56:45,  8.51s/it, loss=1.29, v_num=zw30, train/pref_violate_rate=0.562, train/pref_pairs=18.00, train/infer_cost=8.250]Epoch 4:  23%|██▎       | 240/1063 [34:02<1:56:45,  8.51s/it, loss=1.25, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.310]Epoch 4:  24%|██▍       | 260/1063 [36:49<1:53:43,  8.50s/it, loss=1.25, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.310]Epoch 4:  24%|██▍       | 260/1063 [36:49<1:53:43,  8.50s/it, loss=1.18, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.260]Epoch 4:  26%|██▋       | 280/1063 [39:35<1:50:43,  8.48s/it, loss=1.18, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.260]Epoch 4:  26%|██▋       | 280/1063 [39:35<1:50:43,  8.48s/it, loss=1.16, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.230]Epoch 4:  28%|██▊       | 300/1063 [42:22<1:47:46,  8.47s/it, loss=1.16, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.230]Epoch 4:  28%|██▊       | 300/1063 [42:22<1:47:46,  8.47s/it, loss=1.21, v_num=zw30, train/pref_violate_rate=0.625, train/pref_pairs=20.00, train/infer_cost=8.300]Epoch 4:  30%|███       | 320/1063 [45:11<1:44:55,  8.47s/it, loss=1.21, v_num=zw30, train/pref_violate_rate=0.625, train/pref_pairs=20.00, train/infer_cost=8.300]Epoch 4:  30%|███       | 320/1063 [45:11<1:44:55,  8.47s/it, loss=1.23, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.310]Epoch 4:  32%|███▏      | 340/1063 [47:55<1:41:53,  8.46s/it, loss=1.23, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.310]Epoch 4:  32%|███▏      | 340/1063 [47:55<1:41:53,  8.46s/it, loss=1.18, v_num=zw30, train/pref_violate_rate=0.344, train/pref_pairs=11.00, train/infer_cost=8.260]Epoch 4:  34%|███▍      | 360/1063 [50:41<1:38:59,  8.45s/it, loss=1.18, v_num=zw30, train/pref_violate_rate=0.344, train/pref_pairs=11.00, train/infer_cost=8.260]Epoch 4:  34%|███▍      | 360/1063 [50:41<1:38:59,  8.45s/it, loss=1.19, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.310]Epoch 4:  36%|███▌      | 380/1063 [53:26<1:36:04,  8.44s/it, loss=1.19, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.310]Epoch 4:  36%|███▌      | 380/1063 [53:27<1:36:04,  8.44s/it, loss=1.24, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.260]Epoch 4:  38%|███▊      | 400/1063 [56:15<1:33:15,  8.44s/it, loss=1.24, v_num=zw30, train/pref_violate_rate=0.531, train/pref_pairs=17.00, train/infer_cost=8.260]Epoch 4:  38%|███▊      | 400/1063 [56:15<1:33:15,  8.44s/it, loss=1.13, v_num=zw30, train/pref_violate_rate=0.375, train/pref_pairs=12.00, train/infer_cost=8.320]Epoch 4:  40%|███▉      | 420/1063 [59:01<1:30:21,  8.43s/it, loss=1.13, v_num=zw30, train/pref_violate_rate=0.375, train/pref_pairs=12.00, train/infer_cost=8.320]Epoch 4:  40%|███▉      | 420/1063 [59:01<1:30:21,  8.43s/it, loss=1.15, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.270]Epoch 4:  41%|████▏     | 440/1063 [1:01:45<1:27:26,  8.42s/it, loss=1.15, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.270]Epoch 4:  41%|████▏     | 440/1063 [1:01:45<1:27:26,  8.42s/it, loss=1.11, v_num=zw30, train/pref_violate_rate=0.594, train/pref_pairs=19.00, train/infer_cost=8.220]Epoch 4:  43%|████▎     | 460/1063 [1:04:29<1:24:32,  8.41s/it, loss=1.11, v_num=zw30, train/pref_violate_rate=0.594, train/pref_pairs=19.00, train/infer_cost=8.220]Epoch 4:  43%|████▎     | 460/1063 [1:04:29<1:24:32,  8.41s/it, loss=1.05, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.210]Epoch 4:  45%|████▌     | 480/1063 [1:07:44<1:22:16,  8.47s/it, loss=1.05, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.210]Epoch 4:  45%|████▌     | 480/1063 [1:07:44<1:22:16,  8.47s/it, loss=1.22, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.280]Epoch 4:  47%|████▋     | 500/1063 [1:10:29<1:19:22,  8.46s/it, loss=1.22, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.280]Epoch 4:  47%|████▋     | 500/1063 [1:10:29<1:19:22,  8.46s/it, loss=1.05, v_num=zw30, train/pref_violate_rate=0.594, train/pref_pairs=19.00, train/infer_cost=8.270]Epoch 4:  49%|████▉     | 520/1063 [1:13:13<1:16:27,  8.45s/it, loss=1.05, v_num=zw30, train/pref_violate_rate=0.594, train/pref_pairs=19.00, train/infer_cost=8.270]Epoch 4:  49%|████▉     | 520/1063 [1:13:13<1:16:27,  8.45s/it, loss=1.16, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.290]Epoch 4:  51%|█████     | 540/1063 [1:15:57<1:13:34,  8.44s/it, loss=1.16, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.290]Epoch 4:  51%|█████     | 540/1063 [1:15:57<1:13:34,  8.44s/it, loss=1.08, v_num=zw30, train/pref_violate_rate=0.312, train/pref_pairs=10.00, train/infer_cost=8.310]Epoch 4:  53%|█████▎    | 560/1063 [1:18:41<1:10:40,  8.43s/it, loss=1.08, v_num=zw30, train/pref_violate_rate=0.312, train/pref_pairs=10.00, train/infer_cost=8.310]Epoch 4:  53%|█████▎    | 560/1063 [1:18:41<1:10:40,  8.43s/it, loss=1.1, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.280] Epoch 4:  55%|█████▍    | 580/1063 [1:21:34<1:07:55,  8.44s/it, loss=1.1, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.280]Epoch 4:  55%|█████▍    | 580/1063 [1:21:34<1:07:55,  8.44s/it, loss=1.12, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.270]Epoch 4:  56%|█████▋    | 600/1063 [1:24:23<1:05:07,  8.44s/it, loss=1.12, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.270]Epoch 4:  56%|█████▋    | 600/1063 [1:24:23<1:05:07,  8.44s/it, loss=1.03, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.270]Epoch 4:  58%|█████▊    | 620/1063 [1:27:11<1:02:17,  8.44s/it, loss=1.03, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.270]Epoch 4:  58%|█████▊    | 620/1063 [1:27:11<1:02:17,  8.44s/it, loss=1.04, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.340]Epoch 4:  60%|██████    | 640/1063 [1:29:55<59:26,  8.43s/it, loss=1.04, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.340]  Epoch 4:  60%|██████    | 640/1063 [1:29:55<59:26,  8.43s/it, loss=1.13, v_num=zw30, train/pref_violate_rate=0.375, train/pref_pairs=12.00, train/infer_cost=8.250]Epoch 4:  62%|██████▏   | 660/1063 [1:32:39<56:34,  8.42s/it, loss=1.13, v_num=zw30, train/pref_violate_rate=0.375, train/pref_pairs=12.00, train/infer_cost=8.250]Epoch 4:  62%|██████▏   | 660/1063 [1:32:39<56:34,  8.42s/it, loss=1.11, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.270]Epoch 4:  64%|██████▍   | 680/1063 [1:35:33<53:49,  8.43s/it, loss=1.11, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.270]Epoch 4:  64%|██████▍   | 680/1063 [1:35:33<53:49,  8.43s/it, loss=1.15, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.320]Epoch 4:  66%|██████▌   | 700/1063 [1:38:20<50:59,  8.43s/it, loss=1.15, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.320]Epoch 4:  66%|██████▌   | 700/1063 [1:38:20<50:59,  8.43s/it, loss=1.03, v_num=zw30, train/pref_violate_rate=0.594, train/pref_pairs=19.00, train/infer_cost=8.260]Epoch 4:  68%|██████▊   | 720/1063 [1:41:08<48:10,  8.43s/it, loss=1.03, v_num=zw30, train/pref_violate_rate=0.594, train/pref_pairs=19.00, train/infer_cost=8.260]Epoch 4:  68%|██████▊   | 720/1063 [1:41:08<48:10,  8.43s/it, loss=1.09, v_num=zw30, train/pref_violate_rate=0.688, train/pref_pairs=22.00, train/infer_cost=8.300]Epoch 4:  70%|██████▉   | 740/1063 [1:43:57<45:22,  8.43s/it, loss=1.09, v_num=zw30, train/pref_violate_rate=0.688, train/pref_pairs=22.00, train/infer_cost=8.300]Epoch 4:  70%|██████▉   | 740/1063 [1:43:57<45:22,  8.43s/it, loss=1.04, v_num=zw30, train/pref_violate_rate=0.375, train/pref_pairs=12.00, train/infer_cost=8.260]Epoch 4:  71%|███████▏  | 760/1063 [1:46:46<42:34,  8.43s/it, loss=1.04, v_num=zw30, train/pref_violate_rate=0.375, train/pref_pairs=12.00, train/infer_cost=8.260]Epoch 4:  71%|███████▏  | 760/1063 [1:46:46<42:34,  8.43s/it, loss=0.994, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.350]Epoch 4:  73%|███████▎  | 780/1063 [1:49:30<39:44,  8.42s/it, loss=0.994, v_num=zw30, train/pref_violate_rate=0.438, train/pref_pairs=14.00, train/infer_cost=8.350]Epoch 4:  73%|███████▎  | 780/1063 [1:49:30<39:44,  8.42s/it, loss=1.16, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.300] Epoch 4:  75%|███████▌  | 800/1063 [1:52:17<36:55,  8.42s/it, loss=1.16, v_num=zw30, train/pref_violate_rate=0.469, train/pref_pairs=15.00, train/infer_cost=8.300]Epoch 4:  75%|███████▌  | 800/1063 [1:52:17<36:55,  8.42s/it, loss=1.02, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.330]Epoch 4:  77%|███████▋  | 820/1063 [1:55:04<34:05,  8.42s/it, loss=1.02, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.330]Epoch 4:  77%|███████▋  | 820/1063 [1:55:04<34:05,  8.42s/it, loss=1.07, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.300]Epoch 4:  79%|███████▉  | 840/1063 [1:57:48<31:16,  8.41s/it, loss=1.07, v_num=zw30, train/pref_violate_rate=0.406, train/pref_pairs=13.00, train/infer_cost=8.300]Epoch 4:  79%|███████▉  | 840/1063 [1:57:48<31:16,  8.41s/it, loss=0.97, v_num=zw30, train/pref_violate_rate=0.500, train/pref_pairs=16.00, train/infer_cost=8.240]